{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapreparation import *\n",
    "from simsiam import *\n",
    "from utils import *\n",
    "from evaluation import *\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, TensorDataset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vaseline555/Federated-Averaging-PyTorch/tree/1afb2be2c1972d8527efca357832f71c815b30b4/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "    \n",
    "\n",
    "def create_datasets(num_clients, iid):\n",
    "    \"\"\"Split the whole dataset in IID or non-IID manner for distributing to clients.\"\"\"\n",
    "    # get train and test dataset from cifar-10\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
    "    augmentation = [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "    if iid:\n",
    "        shuffled_indices = torch.randperm(len(trainset))\n",
    "\n",
    "        training_inputs = trainset.data[shuffled_indices]\n",
    "        training_labels = torch.Tensor(trainset.targets)[shuffled_indices]\n",
    "        split_size = len(trainset) // num_clients\n",
    "        split_datasets = list(\n",
    "                    zip(\n",
    "                        torch.split(torch.Tensor(training_inputs), split_size),\n",
    "                        torch.split(torch.Tensor(training_labels), split_size)\n",
    "                    )\n",
    "                )\n",
    "        local_trainloaders = [\n",
    "                    torch.utils.data.DataLoader(local_dataset, batch_size=4, \n",
    "                                                    shuffle=True, num_workers=2, pin_memory=True)\n",
    "                    for local_dataset in split_datasets\n",
    "    ]\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return local_trainloaders, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7fa329d0c040>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fa3280c8b20>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fa32807c580>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fa32807c1c0>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1860, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/usr/lib/python3.10/selectors.py\", line 469, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 202955) is killed by signal: Killed. \n"
     ]
    }
   ],
   "source": [
    "trainloaders, testloader = create_datasets(3, True)\n",
    "trainloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, model, dataloader, local_epochs, device):\n",
    "        self.client_id = client_id\n",
    "        self.dataloader = dataloader\n",
    "        self.model = model\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0005)\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def client_update(self):\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        for epoch in range(self.local_epochs):  # loop over the dataset multiple times\n",
    "            epoch_loss = 0.0\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.dataloader):            \n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                # inputs, labels = data\n",
    "                images, _ = data[0], data[1].to(self.device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # get the two views (with random augmentations):\n",
    "                x1 = images[0].to(self.device)\n",
    "                x2 = images[1].to(self.device)\n",
    "                \n",
    "                # forward + backward + optimize\n",
    "                z1, p1 = self.model(x1)\n",
    "                z2, p2 = self.model(x2)\n",
    "                #loss = criterion(outputs, labels)\n",
    "                loss = D(p1, z2)/2 + D(p2, z1)/2\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "                if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                    running_loss = 0.0\n",
    "            print(\"epoch loss = \", epoch_loss/len(self.dataloader))\n",
    "        print('Finished Training')\n",
    "\n",
    "    def client_evaluate(self):\n",
    "        \"\"\"evaluates model on local dataset TODO: Should this be done in self-supervised learning and if so, how?\"\"\"\n",
    "        # insert evaluate() method of SimSiam\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, num_clients, iid, num_rounds):\n",
    "        self.num_clients = num_clients\n",
    "        self.iid = iid\n",
    "        self.num_rounds = num_rounds # number of rounds that models should be trained on clients\n",
    "\n",
    "    def setup(self):\n",
    "        self.model = SimSiam()\n",
    "        local_trainloaders, test_loader = create_datasets(self.num_clients, self.iid)\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.clients = self.create_clients(local_trainloaders)\n",
    "        self.testloader = test_loader\n",
    "        self.send_model()\n",
    "        \n",
    "    def create_clients(self, local_trainloaders):\n",
    "        clients = []\n",
    "        for i, dataloader in enumerate(local_trainloaders):\n",
    "            client = Client(client_id=i, model=SimSiam().to(self.device), dataloader=dataloader, batchsize=4, local_epochs=5, device=self.device)\n",
    "            clients.append(client)\n",
    "        return clients\n",
    "\n",
    "    def send_model(self):\n",
    "        \"\"\"Send the updated global model to selected/all clients.\"\"\"\n",
    "        for client in self.clients:\n",
    "            client.model = copy.deepcopy(self.model)\n",
    "\n",
    "    def average_model(self, coefficients):\n",
    "        \"\"\"Average the updated and transmitted parameters from each selected client.\"\"\"\n",
    "        averaged_weights = OrderedDict()\n",
    "\n",
    "        for i, client in enumerate(self.clients):\n",
    "            local_weights = client.model.state_dict()\n",
    "\n",
    "            for key in self.model.state_dict().keys():\n",
    "                if i == 0:\n",
    "                    averaged_weights[key] = coefficients[it] * local_weights[key]\n",
    "                else:\n",
    "                    averaged_weights[key] += coefficients[it] * local_weights[key]\n",
    "        self.model.load_state_dict(averaged_weights)\n",
    "\n",
    "\n",
    "    def train_federated_model(self):\n",
    "        # send current model\n",
    "        self.send_model()\n",
    "        \n",
    "        # TODO: Sample only subset of clients\n",
    "\n",
    "        # update clients (train client models)\n",
    "        for client in self.clients:\n",
    "            client.client_update()\n",
    "        \n",
    "        # average models\n",
    "        total_size = sum([len(client.dataloader.dataset[1]) for client in self.clients])\n",
    "        mixing_coefficients = [len(client.dataloader.dataset[1]) / total_size for client in self.clients]\n",
    "        self.average_model(mixing_coefficients)\n",
    "    \n",
    "    def evaluate_global_model(self):\n",
    "        # insert evaluation function here\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        for i in range(self.num_rounds):\n",
    "            self.train_federated_model()\n",
    "            # test_loss, test_accuracy = self.evaluate_global_model() # TODO\n",
    "        self.send_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m server\u001b[39m.\u001b[39msend_model()\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m server\u001b[39m.\u001b[39mclients:\n\u001b[0;32m----> 6\u001b[0m     client\u001b[39m.\u001b[39;49mclient_update()\n",
      "Cell \u001b[0;32mIn[106], line 19\u001b[0m, in \u001b[0;36mClient.client_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     18\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader):            \n\u001b[1;32m     20\u001b[0m     \u001b[39m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# inputs, labels = data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     images, _ \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m], data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m     \u001b[39m# zero the parameter gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "server = Server(2, True, 2)\n",
    "server.setup()\n",
    "server.send_model()\n",
    "\n",
    "for client in server.clients:\n",
    "    client.client_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "averaged_weights = OrderedDict()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "local_trainloaders, testloaders = create_datasets(2, True)\n",
    "clients = [Client(client_id=1, model=SimSiam().to(device), dataloader=local_trainloaders[0], batchsize=4, local_epochs=5, device=device), \n",
    "           Client(client_id=2, model=SimSiam().to(device), dataloader=local_trainloaders[1], batchsize=4, local_epochs=5, device=device)]\n",
    "model = SimSiam()\n",
    "\n",
    "total_size = sum([len(client.dataloader.dataset[1]) for client in clients])\n",
    "mixing_coefficients = [len(client.dataloader.dataset[1]) / total_size for client in clients]\n",
    "\n",
    "for i, client in enumerate(clients):\n",
    "    local_weights = client.model.state_dict()\n",
    "    print(local_weights)\n",
    "    for key in model.state_dict().keys():\n",
    "        print(key)\n",
    "\n",
    "    for key in model.state_dict().keys():\n",
    "        if i == 0:\n",
    "            averaged_weights[key] = mixing_coefficients[i] * local_weights[key]\n",
    "        else:\n",
    "            averaged_weights[key] += mixing_coefficients[i] * local_weights[key]\n",
    "averaged_weights\n",
    "# self.model.load_state_dict(averaged_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(local_trainloaders[0].dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.0.weight', 'model.1.weight', 'model.1.bias', 'model.1.running_mean', 'model.1.running_var', 'model.1.num_batches_tracked', 'model.4.0.conv1.weight', 'model.4.0.bn1.weight', 'model.4.0.bn1.bias', 'model.4.0.bn1.running_mean', 'model.4.0.bn1.running_var', 'model.4.0.bn1.num_batches_tracked', 'model.4.0.conv2.weight', 'model.4.0.bn2.weight', 'model.4.0.bn2.bias', 'model.4.0.bn2.running_mean', 'model.4.0.bn2.running_var', 'model.4.0.bn2.num_batches_tracked', 'model.4.1.conv1.weight', 'model.4.1.bn1.weight', 'model.4.1.bn1.bias', 'model.4.1.bn1.running_mean', 'model.4.1.bn1.running_var', 'model.4.1.bn1.num_batches_tracked', 'model.4.1.conv2.weight', 'model.4.1.bn2.weight', 'model.4.1.bn2.bias', 'model.4.1.bn2.running_mean', 'model.4.1.bn2.running_var', 'model.4.1.bn2.num_batches_tracked', 'model.5.0.conv1.weight', 'model.5.0.bn1.weight', 'model.5.0.bn1.bias', 'model.5.0.bn1.running_mean', 'model.5.0.bn1.running_var', 'model.5.0.bn1.num_batches_tracked', 'model.5.0.conv2.weight', 'model.5.0.bn2.weight', 'model.5.0.bn2.bias', 'model.5.0.bn2.running_mean', 'model.5.0.bn2.running_var', 'model.5.0.bn2.num_batches_tracked', 'model.5.0.downsample.0.weight', 'model.5.0.downsample.1.weight', 'model.5.0.downsample.1.bias', 'model.5.0.downsample.1.running_mean', 'model.5.0.downsample.1.running_var', 'model.5.0.downsample.1.num_batches_tracked', 'model.5.1.conv1.weight', 'model.5.1.bn1.weight', 'model.5.1.bn1.bias', 'model.5.1.bn1.running_mean', 'model.5.1.bn1.running_var', 'model.5.1.bn1.num_batches_tracked', 'model.5.1.conv2.weight', 'model.5.1.bn2.weight', 'model.5.1.bn2.bias', 'model.5.1.bn2.running_mean', 'model.5.1.bn2.running_var', 'model.5.1.bn2.num_batches_tracked', 'model.6.0.conv1.weight', 'model.6.0.bn1.weight', 'model.6.0.bn1.bias', 'model.6.0.bn1.running_mean', 'model.6.0.bn1.running_var', 'model.6.0.bn1.num_batches_tracked', 'model.6.0.conv2.weight', 'model.6.0.bn2.weight', 'model.6.0.bn2.bias', 'model.6.0.bn2.running_mean', 'model.6.0.bn2.running_var', 'model.6.0.bn2.num_batches_tracked', 'model.6.0.downsample.0.weight', 'model.6.0.downsample.1.weight', 'model.6.0.downsample.1.bias', 'model.6.0.downsample.1.running_mean', 'model.6.0.downsample.1.running_var', 'model.6.0.downsample.1.num_batches_tracked', 'model.6.1.conv1.weight', 'model.6.1.bn1.weight', 'model.6.1.bn1.bias', 'model.6.1.bn1.running_mean', 'model.6.1.bn1.running_var', 'model.6.1.bn1.num_batches_tracked', 'model.6.1.conv2.weight', 'model.6.1.bn2.weight', 'model.6.1.bn2.bias', 'model.6.1.bn2.running_mean', 'model.6.1.bn2.running_var', 'model.6.1.bn2.num_batches_tracked', 'model.7.0.conv1.weight', 'model.7.0.bn1.weight', 'model.7.0.bn1.bias', 'model.7.0.bn1.running_mean', 'model.7.0.bn1.running_var', 'model.7.0.bn1.num_batches_tracked', 'model.7.0.conv2.weight', 'model.7.0.bn2.weight', 'model.7.0.bn2.bias', 'model.7.0.bn2.running_mean', 'model.7.0.bn2.running_var', 'model.7.0.bn2.num_batches_tracked', 'model.7.0.downsample.0.weight', 'model.7.0.downsample.1.weight', 'model.7.0.downsample.1.bias', 'model.7.0.downsample.1.running_mean', 'model.7.0.downsample.1.running_var', 'model.7.0.downsample.1.num_batches_tracked', 'model.7.1.conv1.weight', 'model.7.1.bn1.weight', 'model.7.1.bn1.bias', 'model.7.1.bn1.running_mean', 'model.7.1.bn1.running_var', 'model.7.1.bn1.num_batches_tracked', 'model.7.1.conv2.weight', 'model.7.1.bn2.weight', 'model.7.1.bn2.bias', 'model.7.1.bn2.running_mean', 'model.7.1.bn2.running_var', 'model.7.1.bn2.num_batches_tracked', 'projection.l1.0.weight', 'projection.l1.0.bias', 'projection.l1.1.weight', 'projection.l1.1.bias', 'projection.l1.1.running_mean', 'projection.l1.1.running_var', 'projection.l1.1.num_batches_tracked', 'projection.l2.0.weight', 'projection.l2.0.bias', 'projection.l2.1.weight', 'projection.l2.1.bias', 'projection.l2.1.running_mean', 'projection.l2.1.running_var', 'projection.l2.1.num_batches_tracked', 'projection.l3.0.weight', 'projection.l3.0.bias', 'projection.l3.1.weight', 'projection.l3.1.bias', 'projection.l3.1.running_mean', 'projection.l3.1.running_var', 'projection.l3.1.num_batches_tracked', 'prediction.l1.0.weight', 'prediction.l1.0.bias', 'prediction.l1.1.weight', 'prediction.l1.1.bias', 'prediction.l1.1.running_mean', 'prediction.l1.1.running_var', 'prediction.l1.1.num_batches_tracked', 'prediction.l2.weight', 'prediction.l2.bias'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimSiam()\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Server' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m server \u001b[39m=\u001b[39m Server(num_clients\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, iid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_rounds\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m server\u001b[39m.\u001b[39;49msetup()\n",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m, in \u001b[0;36mServer.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_clients(local_trainloaders)\n\u001b[1;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestloader \u001b[39m=\u001b[39m test_loader\n\u001b[0;32m---> 12\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_model()\n",
      "Cell \u001b[0;32mIn[61], line 24\u001b[0m, in \u001b[0;36mServer.send_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send the updated global model to selected/all clients.\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclients:\n\u001b[0;32m---> 24\u001b[0m     client\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Server' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "server = Server(num_clients=5, iid=True, num_rounds=5)\n",
    "server.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"models/simsiam.pth\"\n",
    "\n",
    "# # load trained model\n",
    "# model = SimSiam()\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
