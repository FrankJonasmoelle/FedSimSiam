{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapreparation import *\n",
    "from simsiam import *\n",
    "from utils import *\n",
    "from evaluation import *\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, TensorDataset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vaseline555/Federated-Averaging-PyTorch/tree/1afb2be2c1972d8527efca357832f71c815b30b4/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "    \n",
    "\n",
    "def create_datasets(num_clients, iid):\n",
    "    \"\"\"Split the whole dataset in IID or non-IID manner for distributing to clients.\"\"\"\n",
    "    # get train and test dataset from cifar-10\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
    "    augmentation = [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "    if iid:\n",
    "        shuffled_indices = torch.randperm(len(trainset))\n",
    "\n",
    "        training_inputs = trainset.data[shuffled_indices]\n",
    "        training_labels = torch.Tensor(trainset.targets)[shuffled_indices]\n",
    "        split_size = len(trainset) // num_clients\n",
    "        split_datasets = list(\n",
    "                    zip(\n",
    "                        torch.split(torch.Tensor(training_inputs), split_size),\n",
    "                        torch.split(torch.Tensor(training_labels), split_size)\n",
    "                    )\n",
    "                )\n",
    "        local_trainloaders = [\n",
    "                    torch.utils.data.DataLoader(local_dataset, batch_size=4, \n",
    "                                                    shuffle=True, num_workers=2, pin_memory=True)\n",
    "                    for local_dataset in split_datasets\n",
    "    ]\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return local_trainloaders, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, model, dataloader, batchsize, local_epochs, device):\n",
    "        self.client_id = client_id\n",
    "        self.dataloader = dataloader\n",
    "        self.model = model\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0005)\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def client_update(self):\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        for epoch in range(self.local_epochs):  # loop over the dataset multiple times\n",
    "            epoch_loss = 0.0\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.dataloader):            \n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                # inputs, labels = data\n",
    "                images, _ = data[0], data[1].to(self.device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # get the two views (with random augmentations):\n",
    "                x1 = images[0].to(self.device)\n",
    "                x2 = images[1].to(self.device)\n",
    "                \n",
    "                # forward + backward + optimize\n",
    "                z1, p1 = self.model(x1)\n",
    "                z2, p2 = self.model(x2)\n",
    "                #loss = criterion(outputs, labels)\n",
    "                loss = D(p1, z2)/2 + D(p2, z1)/2\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "                if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                    running_loss = 0.0\n",
    "            print(\"epoch loss = \", epoch_loss/len(self.dataloader))\n",
    "        print('Finished Training')\n",
    "\n",
    "    def client_evaluate(self):\n",
    "        \"\"\"evaluates model on local dataset TODO: Should this be done in self-supervised learning and if so, how?\"\"\"\n",
    "        # insert evaluate() method of SimSiam\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, num_clients, iid, num_rounds):\n",
    "        self.num_clients = num_clients\n",
    "        self.iid = iid\n",
    "        self.num_rounds = num_rounds\n",
    "\n",
    "    def setup(self):\n",
    "        local_trainloaders, test_loader = create_datasets(self.num_clients, self.iid)\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.clients = self.create_clients(local_trainloaders)\n",
    "        self.testloader = test_loader\n",
    "        self.send_model()\n",
    "        \n",
    "    def create_clients(self, local_trainloaders):\n",
    "        clients = []\n",
    "        for i, dataloader in enumerate(local_trainloaders):\n",
    "            client = Client(client_id=i, model=SimSiam().to(self.device), dataloader=dataloader, batchsize=4, local_epochs=5, device=self.device)\n",
    "            clients.append(client)\n",
    "        return clients\n",
    "\n",
    "    def send_model(self):\n",
    "        \"\"\"Send the updated global model to selected/all clients.\"\"\"\n",
    "        for client in self.clients:\n",
    "            client.model = copy.deepcopy(self.model)\n",
    "\n",
    "    def average_model(self):\n",
    "        \"\"\"Average the updated and transmitted parameters from each selected client.\"\"\"\n",
    "        averaged_weights = OrderedDict()\n",
    "\n",
    "        for i, client in enumerate(self.clients):\n",
    "            local_weights = client.model.state_dict()\n",
    "\n",
    "            for key in self.model.state_dict().keys():\n",
    "                if i == 0:\n",
    "                    averaged_weights[key] = coefficients[it] * local_weights[key]\n",
    "                else:\n",
    "                    averaged_weights[key] += coefficients[it] * local_weights[key]\n",
    "        self.model.load_state_dict(averaged_weights)\n",
    "\n",
    "\n",
    "    def train_federated_model(self):\n",
    "        self.send_model()\n",
    "        self.average_model()\n",
    "    \n",
    "    def evaluate_global_model(self):\n",
    "        # insert evaluation function here\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        for i in range(self.num_rounds):\n",
    "            self.train_federated_model()\n",
    "            # test_loss, test_accuracy = self.evaluate_global_model() # TODO\n",
    "        self.send_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "server = Server(num_clients=5, iid=True)\n",
    "server.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"models/simsiam.pth\"\n",
    "\n",
    "# # load trained model\n",
    "# model = SimSiam()\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
