{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(p, z):\n",
    "    z = z.detach() # we don't backpropagate here\n",
    "    p = F.normalize(p, dim=1)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    return -(p*z).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionMLP(nn.Module):\n",
    "    \"\"\"Projection MLP f\"\"\"\n",
    "    def __init__(self, in_features, h1_features, h2_features, out_features):\n",
    "        super(ProjectionMLP, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_features, h1_features),\n",
    "            nn.BatchNorm1d(h1_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(h1_features, h2_features),\n",
    "            nn.BatchNorm1d(h2_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Linear(h2_features, out_features),\n",
    "            nn.BatchNorm1d(out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionMLP(nn.Module):\n",
    "    \"\"\"Prediction MLP h\"\"\"\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(PredictionMLP, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.BatchNorm1d(hidden_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.l2 = nn.Linear(hidden_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimSiam, self).__init__()\n",
    "        backbone = resnet18(weights=True) # TODO: Should weights be pretrained?\n",
    "        num_ftrs = backbone.fc.in_features\n",
    "        \n",
    "        self.model = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.projection = ProjectionMLP(num_ftrs, 2048, 2048, 2048)\n",
    "        self.prediction = PredictionMLP(2048, 512, 2048)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1) # TODO\n",
    "        z = self.projection(x)\n",
    "        p = self.prediction(z)\n",
    "        return z, p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # ((mean, mean, mean), (std, std, st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACwCAYAAACviAzDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABIsklEQVR4nO29e3Bd1Xn3/+x97rrfLMmyLFu+gLnYQGxsBLnjhJBMAoFfbj9anMs0k9ZOAc80CUmhaVpqpp0pJB2HTDsU0jehpOQNpCENvMTcAj9jbGMTHGNjsGzLF8m2pKOjI53r3uv3R17Oep7vsY4lI44s6/nMaGavs/bZe+21115naz3f53kcY4whRVEURVGUMuFOdQMURVEURZlZ6MuHoiiKoihlRV8+FEVRFEUpK/ryoSiKoihKWdGXD0VRFEVRyoq+fCiKoiiKUlb05UNRFEVRlLKiLx+KoiiKopQVfflQFEVRFKWs6MuHoiiKoihl5V17+di4cSPNnz+fotEorVq1il5++eV361SKoiiKokwjnHcjt8vPfvYzuvnmm+lHP/oRrVq1iu6991565JFHaO/evdTc3Fzyu77v09GjR6m6upocx5nspimKoiiK8i5gjKHh4WFqa2sj1z3N2oZ5F1i5cqVZu3Ztoex5nmlrazMbNmw47Xd7enoMEemf/umf/umf/unfNPzr6ek57W99kCaZbDZL27dvp9tvv73wmeu6tHr1atq8eXPR/plMhjKZTKFs/u9CzG233UaRSGSym6coiqIoyrtAJpOhe+65h6qrq0+776S/fJw8eZI8z6OWlhbxeUtLC+3Zs6do/w0bNtDf/u3fFn0eiUT05UNRFEVRphnjkUxMubfL7bffTkNDQ4W/np6eqW6SoiiKoijvIpO+8tHU1ESBQID6+vrE5319fdTa2lq0v65wKIqiKMrMYtJXPsLhMC1fvpw2bdpU+Mz3fdq0aRN1dXVN9ukURVEURZlmTPrKBxHR+vXrac2aNbRixQpauXIl3XvvvTQyMkJf+tKX3vGxW1beIsrctBQIBOTOgZAoGrZz0DWiLsSO48JxfLBfBRz73VBQvr8Fxa7ldxV2jH+mXxRFHzywc74t5+EUHrtOF+pyeU8elxV7fvePYzbn05/+f0QZ48QMDAzYY/qyrZUVlYXtiy++WNSh7ujEiROFbQNtTSaThW3Pk3X1DfWiPJQcLmxHIlFRx/VP3fv3i7rR1Ghhu6KiQtSlU2lR9nzbuUFwY/NZ29HFDcuVVbZ/QiH5jOSyuTG/Fw6HRTkxNFTYjsViou7KK+0/Gtt/v51K8d3vfrdkvTJ9KHUvP3v9Xxa28558ZgMB+VPEh1p1nRyjkTAru1lRFwzJ5zQUtM+iPKN1biAiCsKcjwEoPC/PtuUkZ9iRi5499tvhwBxroEX81yKXk3XZrD1nPivbmhjOiXKeTbJheL6jIdu+UATvARw3bo+TTMh+/cXj99A75V15+fjc5z5HJ06coDvvvJN6e3vp0ksvpSeeeKJIhKooiqIoyszjXXn5ICJat24drVu37t06vKIoiqIo05Qp93ZRFEVRFGVm8a6tfLxbuK60S0nNh7wc48C7lWt3DkAV3xU1Hy5INxxmq0PbOy/6U6L5cKA87i9CWRZD7APHg139sQpEgfGeH4i4UjcxEh8V5aH+RGG7ob5Ofjdo7ZzD8SFRlxyS5b4jRwvbqeSIPEc8XtjGMRE/2S/Keaa1cWBMHD1k3cezWWmj9pmOIzWcFHWJxDBJbGeGQc/ENR/oPYYBf0ZK6EOiUdvvTlA+T0P9A6KczVtbM2piBgYGabyMjtp7m0plRJ3Dnne0kRs0zPMxO+6BX8yZPrWGaY/Qfl5dWSXKgdOFni4zvLfw+vmUgr3qTiAFRj5vv53JgN4AusPL2f7L5eSc4pB9hlyYYEJhKIe4hkmeIxhiz1ORw6W8Li4rQ1mdx/QrbiAv6kJh+wy5LmpF5DPjsLWAfF42Npux5UxKniOfl+Uc06dwDRcRkWHPd7RCzrGBoGxfJm3bl07BpD8JnF1PgKIoiqIo5zz68qEoiqIoSlmZdmaXICwF81U/XEI2RQuI3O0JqthXcXkX39C4d22gaI2SLV1No6y8RUvYRfC+A9MOW+I2WIf3YJxJlMMx6dY5u322KCdGrdllNJ0SdXlmDujr7RV1x44dE+XhYWvayGbkkn84ZpclU+D2emJAml1qqmsK27gUPMJcdisrK0VdjpldEkMJUcdNMkRyeTXjgxsu83+OenKp1Q1JE0Awb58hXLKtzFvzADfBEBGNpKTpi5uXcnAcNMOUIsNMUXyZmogowJ93Xx7TdXEcsgfzHTx6Z2qx4a0bGZV9VbTELuaqs3uecNkz6xcZXsbf9oYmO/b5kv4fDwOu/uw8Pp6Sm7cc+AkDs3M2K8clJ+SzfcGWbNDWztoTKHbaLWzhmDTsB8KAZMB4su0+2WcYwzsImxGGd/Bl2Qlw842cQ/hV5nw5T+RkkbLcHfodmDHHQlc+FEVRFEUpK/ryoSiKoihKWdGXD0VRFEVRysr003yEQPPB7G2oLzAG/WnHDnUrxSNwTjC/SZMbuIEZbhucAszk2I9RA8J1MBjO3ONlCD3sg1/aOCUfFKuQ4brntM8R5T17bZj0XFZqNeL9Vo8xnJTuq6Ngi+faBGwa1xtU10h3VdRK8KGHmhgewjyXQzurLY+Aqy/Cj4uaijxzr8uC5sMD7QgP445tzXvWFTmdkboSHBMYmp2D11kK7pZaAVqfYNDWjaTkdQyPoK7COeX2RCn1TV5XJEVglQlwm07npIu1CHtd9My++xoQPCW/liIPZtbt9TUyBUB0AklBwywsejgCz0gY/FfZJIuajzRzNYWhTQ7oHzwRilweKBaz7QmEZF0e3brZiYpcdtkzFAii5mPsCQ/bzvUZOMfyXQNBCDeBWhJ2A4s0H2x+Hh6Wc5iBQSHnv8kfk7ryoSiKoihKWdGXD0VRFEVRyoq+fCiKoiiKUlamneYDdR2OsLWDv7NfwpYKr13c3IW+2gEou8wC54CB1DEsdDVqTsqA75wu1sn4QEulx2IsYAgHHl7YQGWxxmN8fcLjb/zxHPK4PIT4AUhTz43EqEvAMg93jpqGVMrGD6mpqRF1qJXgx0mnpVaCtxVjd6AGhYO23XTaalswPHckZM/hQvAZjH/D9RgujBehgTmNxoPrXvC5xBDvpfDYaPPgmQ0a2wdvHTkh6gYh/HxVzOqE/CIdxfjjFIz/iRlbODE6KmPPRKOgZRGpIMZuG8bNwedZaN5KhODwiyphruTzFpyzP277eeHcVlHXOUeWS8E1Bj7okiB8E/HwHW5Q9h0fIx6M0SCkd3Bd1j8oAQzYfYMR+ayFitJm2HO6Zux4M/jbkWe/FTi2DVyzK+KOyOvg1+VjLBHQjpBjryUUkteRTtt7kM9BCHlP7htg8UIi4cn/LdOVD0VRFEVRyoq+fCiKoiiKUlamndkll5fLdQG2loZL0WiGEe6QJVxSi4w1sMxm2BKm58ESu2Pb55BcenZ8uxyGy92+C+eQKTrHbCuC4Y8Ne78sckXmYdHhe0WuXmxJ0Pi4XMeXFmV7isKrjzPk/BtvvCHKr7yyQ5QTCeYSCmYOPibmzJEuunGWqZZImndKmRnQdRSzlnLzCR6HZ5XFrLZpCNvOcTx0HbedG4CstkHmxlgRk27K2D/cXBIOyyXtGPsuuhMnwBRWyVx2ufvuqcql4FHTPRh3WeZCjHXz58iQ+811NjQ8LscXjcPxMoGv8WckCa62sQo5FwSD43XEx/8PSzSoyMbJ0x7Agwnzn8vGFneJJSLa13O8sJ3Pn3l2U2Feg7Ht5cB9n7XXceUzw0PTOy6YXTCrbZiZRDASu8hALq8Ls5VzE0QK3Pe5qaWySqZPcNl1oskMTU2umI/h98Hj+8mxk8/L4/K5CpUHQebCjMfJZTEsAstCnNOstoqiKIqiTHP05UNRFEVRlLKiLx+KoiiKopSVaaf58Iy0/xmmo0Adh4tx0XmxhDbBB9tcDnYOMzviwZ4D8jjxQ3a/WIOoq4jNKmzPmTtf1OUJQt06YxWISISUhxpIDe0ww6brj60zycH58+AmzG2QxoC9mrmPot6BwC3MQ1HIGOQgHDW6sDU2Nto6+G6auTkOJ2Saekxpz/UYqI3gLqqlXH2JpMbBgDstuteOdY7B+OCY++E5pasmUVXE6h3wGpNgo+YuxFVVVaKO3z88RzXsyzUhQ0NDou7ESekWW4rX98cL2zHQqwRY6Oj9R6Tm5MCgHBM11VargDqtCYk3SumS+PjG/dhzmkzKkP/BqNw1yAz+BjVl3HeyKHw4ut4yF8yi6ZzpJiB9ugF7v8eSQSzvBN0E0wm8k8zqIZYaAyUoDsZQZxoMnNO4+yw5qJWTuAHudgphyF2uQZH947rYPxburkok71csJrVOfC5AHQdOlfxe4oUY1gKU3WCmB/4MYyj4EHOZRddafER8PueNU6s3EXTlQ1EURVGUsqIvH4qiKIqilJVpZ3bJE7g88qVF2Dfgy/Uol+eZxRVTtsLkk3Q1wyiDAWa+yCZlhMpNP/tJYbuisk7UfeRzXy5sZ0ILRF0+L5fxXb7uNoEVLwMuY7x/XDDf8GVzD8wuvoE+YEt5PppOSqSq9TH76jiznaLpIAh+ady11QW31+GRJNtPRpqMReX6d4ZHJs3IpfIsM/3U1dWJujRk0h1J2fZEI/IcKWbOwey4CxcvLGwHYKm3qalJlFtbbTRJbE+YmWTQRDSclOaKbMZeVyot+yc+GC9sj6bk2EYTzZEjRwvbI5g9OCWPW4oTg7Y9VRk5tmJsqT41KsdoTUSOu0TSfjfrje3K6hUtzhfNHGwbXc5tG8ASKKIAp1LyexFwJXWD/LnEZ40tseOzlUd7BTPfoOmCRR7Og6nUgBmmv+8Phe0FldI9PVZlx+x4zaanIhK2bcXoz2iq5P3uhsCczsMUgB3IBXsOd5F1A3BO1/ZBLo/zlBy/FeyZDoflXM0zZ2dgfpNNxUjZGK3bHjcP/cGtQhhh2vfA3ZgNzIBMwU4OG3fGl3NqBPqZm76LxuEkoCsfiqIoiqKUFX35UBRFURSlrEz45eP555+nT37yk9TW1kaO49Bjjz0m6o0xdOedd9Ls2bMpFovR6tWrad++fZPVXkVRFEVRpjkT1nyMjIzQJZdcQl/+8pfphhtuKKr/x3/8R/rBD35AP/7xj6mzs5PuuOMOuuaaa2j37t0UBXv7meD7Mhy0kEagWQrNo+xVC3UC3PyGNjUCWyGvb5sl7fKXLZhX2M6C66afGShs54ysMxSDcinNB79QcGXFsO1Mr2LyELqa2YE9zJ4J9kmu8/AhjSIPG2yMtMtjWPIiV9wxaGhoFOW+vuOifOyY1RtgyHIO1nE9CBFRimlCsuDey91woxAuHN1nW5hGZdGiRbKupaWwzXUbRER11TZbLqYHQPi1BCPyOQgwTQxm3MWstryM94PrRbDv0GX3V7/6ld0X0h7U1tcXtkeOSc0JksrZvsyn5cOXZE0YystrroL7FQtbjUoANEL8KosDRWOmWK4NG1vzgfeLawEyEKI8AveLZ17GsZTM2+sKDQ2IusER+Y9cbPYyuw3TuZOzbcjDTJ/pPSLKI7t+U9j2LrhOHqfG3kvypNZpIrz+2q7CdiAg+6O+vk6ek7nBYpZmniE4HIFsylF5oWGWIsEBPUieaSWyaTl+Eynpoj/MxgSGIec/LKmUHF05Jtbwc/J7mFphgOmt2ud1iLoQ6y/0ei36KTN8PpZ1XKh07ABkA3flmG1pa7PH9CZf8zHhl49rr72Wrr322lPWGWPo3nvvpb/+67+m66774wD+j//4D2ppaaHHHnuMPv/5z7+z1iqKoiiKMu2ZVM1Hd3c39fb20urVqwuf1dbW0qpVq2jz5s2n/E4mk6FEIiH+FEVRFEU5d5nUl4/e3l4iksvMb5ffrkM2bNhAtbW1hb+5c+dOZpMURVEURTnLmPI4H7fffjutX7++UE4kEqVfQDzMi8z85cH4hX7U3NiLFixuv3XwFAZ1C/Y86dERUZcbtjZaJyttejuftXZVCsmYCZ2LVsimstDWRdHVeapsMOoVhUVn1XjNeWbH9CFsswP+/EbYqOWReHhhA7Z/LI83Zgmmesfw6jxEOIZF56A9HeOFzO+cX9huhpfm+fOsfgdfqEMhtOlbez/ekwyLH5KEmBsDJ04WtjFWBq4C8rgs8xd0ijquSUHNR6ky6kH4dWEd3hP+nD755JOiLh6P03hxWK7zIOirQrwMYchHc/JeBvitNpiGnR2zKFQ0hiwfe6KIsvYkIJbJnr09he3u7oOi7mS/DDefS9jvRrPyvi9L2fFyIic1VF5QhuCfNc/G52g+T8YOmnP+pYXtA2++IeqOd+8S5RQX1zgyjoUI+z2RoEPAjzbeXdiOQnqCpqZZolxVYbVQ4aDct7LSzp2NTfWiDjUf1bX2OOmMHBNZNsfV1teIur37/iDKs2rteToXnifqDhyyKTUuuuQSaI/VORqYm9NpObhyLIaLA1ojHq8DMwd4MN/wqTwIsYOibNrqfW2nqMtA2PiWz36msO2GJv9VYVJXPt4W0/X19YnP+/r6ioR2bxOJRKimpkb8KYqiKIpy7jKpLx+dnZ3U2tpKmzZtKnyWSCRoy5Yt1NXVNZmnUhRFURRlmjLhtZRkMklvvvlmodzd3U07d+6khoYG6ujooFtvvZX+/u//nhYvXlxwtW1ra6Prr79+UhocQBdV5vp1sl8uSVZUSPfVYNCuOeVgOTPEXRUDaFaQ7mU1dXaJMJOWIagP99jl1nT8pKijsF3V2W3kEnYMMs62sCVTD0wiOeECiZl8x14ydTxIf8jMLh6hayK4F4tQ9ehqO3aI+yCYwkpleOWchKyo6ObJTQcepHXkLmwj4Fq7cuUqUf7oRz9a2A6De2SGLdMOMTc4IqLhYXDFG7bnQbMLN1/gir8wA2ElmD34EjKGV+dmHzSLFSVfZdvFkfLtB/iMYHnp0qWFbTQR8Sy/o6nSIvJgwJrmHFiadpiJ04X1ZvzPiacPMGhG5JmgweUSo5I77P5FIbPvwSN2XG569XVRt5eZWo4fPCTqAmk5Dvn4XgDm2Y4Gmw37pfPlinFjWobn7z9kzXj7B14TdUt77TlGSK5Gh1x5LwfzrA1FkenHdu2fCC71F7ZjrryOwaNyrjwyau9RRYVcDY9E7dhqam4WdakRaQZ3mQ09CyHuMyykeg7MdIke6Ya66LzzC9sBV7bHMClA/IjM7lzTaDtzdET+Vri+/H2qn2XNmPkUhNzP2evqOSDdpPGecHffaFQexwna+55OynFXVy1NWCeO2vAGHvrzTgITfvnYtm0bfehDHyqU39ZrrFmzhh588EH6xje+QSMjI/TVr36V4vE4vfe976UnnnhiUmJ8KIqiKIoy/Znwy8cHP/jBkoGiHMeh733ve/S9733vHTVMURRFUZRzE83toiiKoihKWZlyV9uJ0v3WNlE+2nOgsN3DtomIqqplWvYQs4vzlOxE0vaez0j30BC4K616nw2idvxN6ZLFpRsYcjqWtpqUEXDl2gy6hYZD1m0vViNDjSeT1v6Hmor5c2U67NyIPWc4CGm+Yyx8eL10bx6FcO8OO48HtvccSy8/MixdScPgkjreVOsZcIvDNPGNjbZPAiBqyKVZKugsuP7CcfYz/RK67HJdCbqZostuRTQ65r7cfRW/5zAXNtTDZEqEjc/DeAkxbUJROHUIuc/9TgPBsW256KKL1NZal8dPfepToq6ShZv/+f9+uORxeJr2CLgYcgmIA/fOhfTyLjsOppfnOg4HNEtBV96TLDvNnhNHRd2uYzZeUUWbdJdv96zNvKpSnv/CFUtE+TUmyl+6R+pDRj9s3e7rIZR31agcow1sTku31om6P+y2x718iXy+K5sh9cOg1asY790J9Hj5lRfZ84ekGR51W6Ojdk7BVA98fEfAmh9w5JwfDvB5Xe6bGrLz6L69x0TdVe+XoQ9G2Tyyfcfzom7R4sWF7YOHZN/5B+y2AS1hTU2tKPcet89iZkSO9aERO+66D74p6vJpmCvZrc1Duot9PXZMNFdL9+aUC1q1X/53YbulvkHUNXbI34czQVc+FEVRFEUpK/ryoSiKoihKWdGXD0VRFEVRysq003xs3fw7Ue4/af3XMxDq3Ad7l+cz/+eYNBbOamaxO0alcTANYWf3vf5KYXvgwB5RF+H2/kppF8sOWZ1JPiX9wem49Cvfn7A++tF6GdrbDbC2g67EOSRtns4oS8ntSb1FpMr6q1c2y3Ddg460Zw+wlMoDSamXIRYDJH7yuKgKQJwErrX50IVj2w09iEkSgXDMAaZBQZ1JZaWNAxACjQWGRecRdTF2Brcto46iKKw9s1mjVoLvm8uhBsV+Lw+aBtS58LYPwzUfPWx9/1FXghoUh2mYnKDsj7Ha/cfjSn1IKGT1RVyDQ0QUjcr7VYrhhH2Gq2ZJzRKP0+Biv0K8Di4NMBgXncUvgQjulEzJvnyTxZzYdfAtUZdx7P2qapR28NSgvQ4f5pDU8cOivIwJEI6HZFsP7vl9YduJtIm6RLV8Zlrzdh4JVzaJuhPtVoOyb5cM9965UI7D1jZ7vypiMNZFN595avUAG7+jMBc5AXlvK+vZuJQNEPomh+QzEg7LcVdXbcdlJCzn/KGjVp8Rh9AZfQl5nDgLhx8Encmbb9m5O5uT1xVgz3BLs4wP4pKcq7NZ27fPPfuSqJs92461uajry8o+4CGZRmAc7nzdjtEX98qQ+yOQRqSj0WpS6s9fRJIl9E7RlQ9FURRFUcqKvnwoiqIoilJWpp3ZpQGWHSsCdlntUDeEeK6WS2eDg9btNAKpa71R+10HXBxDsOx36K1XC9smCVkmZ9nlsXxGtmc0bpd3q8Bd1RmRx6kJ2uWyaBpcW/P2nTEErokuVYiyN2rPGQe3wUDM9mXFyV5Rl4/JJcKjw3Y5MQPuvZGQLQd8cPvKyLbLOyJNPZwMuMjye0dERMwtNQ6hz7Np8KljBDDzMXM7nYgpBU0ivHy6rLKijvuSgqutU8JdNAuuyEeP2nuLZpf6ehk2mYdjLrWIPgwZeNH01NJiTZWHD0uzwkQiGp84+nJhOxFvF3WeY80Og0lpqoxA6OhIxJr8omBOirL/swLgOh+HUPkDJ215VgLce9kz7OyWIcGbhm37TJ9MD1CzQ4Zib2BpIR7PSFdb6rNtv/Q8aTLz/Dp5XBZKOzskTSuxmP1uVQ5Mb8elmSyetu3N5uTYirGfCUOYomH8hEbs3GR82R6etZVIhsM3MP+Sa/vHg2crXyHnv3yUueQHYG6M2dD1FXNnizo/OCDKzdXWBOEShHuP2VmtsgrMmHk7b/YPymeEmy2JiGJhey3Llsr+mM0Ss9ZUS5M4gfkxn7O+tj6k21hw/nsL2z956H5Rt+33O0W5rdVmSb58xWWi7nB6fCETSqErH4qiKIqilBV9+VAURVEUpazoy4eiKIqiKGVl2mk+Anlpn42StW91tEhbWH2DDF+bqLf2r3BI2hy5PTtIYI+EsLPE3D5DzTLldX44brcxVDQzT2J4bC8l7Xb1tbYN4ay0dceYXiUENs+wL98nM8wVzYDOZDhuU1yjO1sFuF21VlobfmWTdDH0fbtvDkJVo/vouF31QCaBLqoe0+UEQYsQqLBaFnRJ5WG/iaT7damEiQjuy8tYxzUfWOfy74Hmw4e+Mx5LLw/3nbvhosYkBSHtue6lVAT1PGifXNDLHDpktQoJ6OdFCxeOfWCgImld1y+YJ++PG7XP8GvdMiR4LiX7Mtdv2zs4IttuWNkDl/zIiJxTWodsOZaQqeirh5OF7cAopBJguegh8jv5YTlGg6zjP5OW+piBGqt7mX1S3qAs6psM04ZF5DXng3b8eGl5jble2R6/yWoc0lnpSh9zzty9lhN2uOZCnj/kSm0CH5c8/D4RUZjNMS5oRXxP9tfwSXstx8ANtrH5ksJ234DUY8xeVCfKy5ctK2wf7O4XdTz1RPMs6Ro9mrD9un37a6LurT1So9NQZ7UkeB0mbbUruVlS95jOy+ci49m5cvGFF4q6VvYbWVf3v0Vd3pPjx2Hj2WRQw6WaD0VRFEVRphn68qEoiqIoSlmZdmaXplpwkc3Z5eZwk3Qfy4HLWFXUZnF1XXSHtO9hsZCsC5A8js8ykYYhal6qwtbVVMilxCPMZdYblstWFXCcykq73Gx8MDkwk40LrlQivB3JLK5BiP5XwV89IeVjKiWXXnPiNRXc7Qzrn6ysw0yk4zVtoJkFM77WsyyLwwm5pNzUZCM9JpNJUVfquKUik2Idup1i+8ZiQm64JeqqqqSJccEC6xaHbsDY59LsIs/Br6OpSWa9DEJ02IOHbeblt96SEXobG6RprhSZvG1vMi5NO93d1sW6+whkDD0hl79Dg9YMYuAZpow1XS7OyuMshOcrlLBjJubJvvPY9BMOSPOsz0yexyNgZoG+SzNzSWW1NN3GXPsMmZR0j/fS8ppTo7Z/co7suyw7Ti4gx2d/Tl5X1LH3K4YhPBml8xyXJs8iePpgds6DnSrE5jV8DDzuzm/kNY968l5u3rGjsF3VLKNyLqu3z9Cbx2RW25GQHCMN9fYeneiPi7oIC1mQ9WSo1IFeW+45Is0sfb2yHGVZx4dG5e/DFcuZvCAu57R0v3TrbgnZvg03dMhzBux19vZKd2IXxk+EuauPJiCqdTW9Y3TlQ1EURVGUsqIvH4qiKIqilBV9+VAURVEUpaxMO81HPivd24jZa30jjYNBF+301qaFIagd5k4WCUOdAZ0J0zz4WenmVFllXQXraqRdfuSwddsbGpE2xkhYuk/lWSDyLIQaz7HQ2lm4hTHQfAwnrVthSh6GIszd2IGQ00Oj4LYXse2rxhDlLNwxePOSgXvCXVtLEYFMrBgWvam5ubBdUSnDJmdS9p5gaHG876jdGItS+gusL6UdKaV5we/hNfP6Utl5UfOB4HHHaitBW8OQWfhAj3W13QsZMhctXEDjpbLCanT27ZMah//5z+dsISSfp07IvnreVVcUttvfI+37IdfarC9qkGOrAfRWJ197s7CdfUpeV3TEPl8nIBvukye6C9t789Kdd1VE3q/2tK0fJchMzd3RwXXdhyzR/PH3ILJ3iGnTcg3yOeiOyPlmVt5eS9iV/TEBD/TSeFzzAdor0NYEmJsn6vPyLLxCMCJds6sici44v2N+YTtWM1fUHX7l+cJ2Y1+PqMslpQZla4/VblTE5DmqWeiBXE2dqOtlxw17ckzMq5bCiXqmHQk1ymu+gGUvbj6yU9Q11Uut44J5Nm0F5pZ+fchqhJKQ0mNug9QeLZhjj5PLj2/engi68qEoiqIoSlnRlw9FURRFUcqKvnwoiqIoilJWpp3mw/NlPAqXhQU3hDbzEJRtfZGpn2k+PMJYDBhunR0HfKN5FnQP4yuEmTYCwox7YFMbHbF2zeyItC07vq3LZGV/eDFpFx9KWn/xwaS0OVbHbNshLAElIA5AqML2gfGkzsVjodj9IGg8CFPPjy8eRm2NTFs9f/58UY6xEOo56APDztHZ2UmlKBXLYyLw7xbFABHXPLYBHb9XSh+CdaOjVtOwe/duURcG/Uwz08ugPuTkSZsmHkPR4z3g9PX1yuP023gUlVVoeZYMHrfXnTkkw5mHXTt+h9Ny3C29bJkoX3XTRwrbEZYCnYgozUKmN4RkDIXwgIxhEE7a9gyk46IuMWzt5FsvlWnY45ELCtsHtslQ2nvf6hblNRH7nNaCBCcXtf3lhmFOg/ETZHFZ0kGI8cPqzKIVou59q64Q5dHXrf6BQDtCkxRePc/mOIdQjwe6DhY7qLKiTtTVNdrw8w2NLaKuvlLqH95zoe1cmLZo+IjV9pgqWTnU/aYo+0znF8rHRV3ghI27YfpkmPbFI1ar0QVzWk2l7OhmFtvEg3tZycLIV7dAXJg2GcvDsFQYqcN7RV36uI3HMzoaF3XtDVITc2LQPhcBT8YWCdaPHQtmvOjKh6IoiqIoZWVCLx8bNmygyy+/nKqrq6m5uZmuv/562rsX3qzSaVq7di01NjZSVVUV3XjjjdTX1zfGERVFURRFmWlMyOzy3HPP0dq1a+nyyy+nfD5P3/72t+mjH/0o7d69u7BEe9ttt9Gvf/1reuSRR6i2tpbWrVtHN9xwA7344ouT0mAnAO9LPq9DF0IMHc1cvYxc1uJL3gZC/5ZajjckzQgOC2PswxKpE7HdncxIU0HIgfC17DITQydFVSTAd5PXnIzL48TZtQwnZZ2fst8NR+Vx+iHceqNv3ck8yH7IbwKarPLge2vGuYQ7PAwhhGHJvbHRLq86YIIINdh+RrMLN08QEQ0M2BDDpVxQT0cpV1s3yI8L52BtH2+I9tOdH803E3H95SaaaFQurTpw3DwLVe+DC3U4jGv3YzN4yC4FtzdLF9BVC61po+cP8jnoffWAKL/4rX8qbDdF5NTWUmvHbygqryPaK10Oh7r3FbZzyeOi7sRKa1rJL5sn6sJ7rOvxRYulq+8OSFew96Q952XQVzlmHwhBJgMPXMUD7B5hSPlhdm9j7XNE3fx5su39o3bJvQpMF0l/knxt2ZyLFsVISLqdts1eVNie3Sif4bBrx0gY+oeOgHkgY8tuQJr/amZfXNgOdV4k6twRGXo8w8Kk5/pliHt++wJJ+b08+547JNvmjkgzuMnY8Z1Oy+fJYSabwIB8Do4cjYvy1pRt3xII096bte3LpuQ5Dhu5SHCStff9S5eLukaS4+lMmNDLxxNPPCHKDz74IDU3N9P27dvp/e9/Pw0NDdH9999PDz30EH34wx8mIqIHHniALrjgAnrppZfoiiuuONVhFUVRFEWZQbwjzcfQ0B/FNA3/N4nU9u3bKZfL0erVqwv7LFmyhDo6Omjz5s2nPEYmk6FEIiH+FEVRFEU5dznjlw/f9+nWW2+lq666ii6++I/LV729vRQOh6murk7s29LSQr29vac4yh91JLW1tYW/uXPnnnI/RVEURVHODc7Y1Xbt2rW0a9cueuGFF95RA26//XZav359oZxIJEq+gOTBNdBltsNcTtrMIdsycbkI2roNO5Bx5XFc0JlkWROK7Os8RTscJ1BtbZVpcEHFFZ9kztrbBpi7FhFRiJ0z6oGuBcJuV3RYm3kAbcsn43Y7BNoReC2dXWPdLjNgA3ZYCHXPB32BD+6j49Q15HIy/DJ3ASWSbqD9J2RK6WTCuia/vTr3NqgB4eHWS4VaL0o9j+PH4ftCOnWm+QhAGHueWtw7jdaoVPu4PuOyyy4bc79THXesOtSgYFp43gMZ0DCVchNGzltq70nzfKkzCTXa+7d1+xZRlx+V15Hpsf3nQFjyupg97jGSmiUPXNkNy0OQisnjJC5ZWNjufkO6VS6Yba+jolba8weScoxmc7a/vAqpc+G6NpjSaAjmv8Mj9lqO5+V1DTi2P+a++bqoaz9Phr9vaOSai1L/k565O7rH0t2HwvI56KiQ4d9n9dtrCRzcI+rybKxFo/KZCYO2JnvSzqsZGJJmtnXZrZrdIOuy8v4R08AF6uX9CkXZ3Hj0kKhLDtp0AW5K6tbCoD8LMd1U0JE3PnvC6jhGc/Ie7IK++3ncjrXzI9K9t5+lSMjCOUxatqe22uq/vBxoEieBM3r5WLduHT3++OP0/PPPU3u7vYGtra2UzWYpHo+L1Y++vj5qbW09xZGIIpEIRSKl4wAoiqIoinLuMCGzizGG1q1bR48++ig9/fTTRf9FLl++nEKhEG3atKnw2d69e+nQoUPU1dU1OS1WFEVRFGVaM6GVj7Vr19JDDz1Ev/zlL6m6urqg46itraVYLEa1tbX0la98hdavX08NDQ1UU1NDX//616mrq2vSPF1ysDQdZO9PRW6v4NbIl/xLuSNiFE5cpeard3icHMtAi66JDY02e2dbh3RVSvZITUyeLYn54DaY5xErI3KZehZEv2tcYKPfDR6UGUP7E3Zp0YEomHNam0W5sspGZCxyCWXFvFd6ud0fp9teVZWM1IrRNvsH7DLk/3nqKVFnWCRFdJ+9+uqrRfltvRJR6ayyeJ/xuAFukoDxws0VuGhtvLGXsUuZWYrMhhMwc/D7h/ey1HFwX54xeOGChaKurs7WjaZKi8jrWZTK7VukKePgUev+d9CRz0EG/CwPeXZpOAFJOEeY2a4KLjEImWJd9oSbNvkcnGQZrhsq5Bhd9aEPFLYP9MhnbeDwflGOsYymB7PSXHKYucT3ZeRSfSYox11Tu21frFZmW53DImZWw0wfyEmX0I4FbYXtMIY7zvP7fuZmF25KrZ81S9TNunSpKG97flthu/u134u6KIt+WgXNOR/mv5Y6ayLJJuQ1V2XZPUnLiLi5P4Cr7agdUG/BPXg+bueii0ek+fF9jm1rypHjNQm6AO4UOwRjPRm0c8gIeLF3t8q+vOSySwvb/+e3vxF1YRa+tiIo5/y2RvmbdEGnfaarIev6ZDChl4/77ruPiIg++MEPis8feOAB+uIXv0hERPfccw+5rks33ngjZTIZuuaaa+iHP/zhpDRWURRFUZTpz4RePsbz31U0GqWNGzfSxo0bz7hRiqIoiqKcu2huF0VRFEVRysq0y2qLqy8ec09CF0dcqOEus6VCTgfAtbbI5TA4drfJc8r9HGZbrm+WIYxHT8gwzpUVVuMwb6HM3mli1lbno74A2pYN2WtxK6RXUYi5HxK44dYzfQqRdBHNZKXt0ufZKsGVFLUR49Um4H7oysnDpKNb7pxW6148AiGMjxw5Isr8u7GYtGvyUOOY/RXDvTfPtudsbpY2WH6OohDuPPMoujDDGOXlovvMdAOnG6+8DaXuTxa0CBiaPsq81FpaZXbRCOs7iPBcxKYXthe2d+0/JuoyJ63tfVZMhuDuzMn2HYvYMZxMyfueDdrrykE/R8D27TKX1eEm6YLZz/QY7bWQXZS5j/Js20RE8bRs63M9PXbfmHwuG9tsX1555QdE3apLzxPlRe123wjc5xC7Ls+Xz2wmJ28Kv9cOpoVg5TNPACD1YK/3yPt8NC2zAPfE7X3fm5Lu8jyLdk2NHBOVl8u5ctYl7ylsm+EDoq6q0WZ/9rul5s77zT5RHiCrp/mlkfPNs4N2TnndkfNosNLOC2nQ0qQh3LvLstFKhRtRPRs+JyBMu6mRvyXve9+HC9sH35K51zzPzqMjLMQ/EVEDhNWvCFlNUz4rr3ky0JUPRVEURVHKir58KIqiKIpSVvTlQ1EURVGUsjLtNB9oBw+xsODhgLS3Fdku2XdDECo6z+KHYCyKEtGoS2oYDJw/w8MfQzjzNNhk44PxwnYj6CgizM6Z9ktrEaIsRogblbbt4azd1/elTS8yIo9TXWWtkF4eYkOwYigo32dRK5HPYw7sU4P6i9lMU0FEdIjZzEMlNDiYFh5jZ3AtSZGeiLUddRSHDskwyjUs5XU+WyfqjrC24nVwPUZ3d7eowzG6oNOGxA5DXBauK8FnBPfl15lMSvsx7y/U2QwOShsx14tUhMF+TeNn2LH29CNDcrxwrVF/QI6dIU/qFqLsfg24ct+TrAtmhWRb60Dz4ads/6QhZHkb69rDR3pEXfdbbxS2R+JSc9LSJLUJN//ZdYXtZReeL+oWddiYG3U18jnA6SabtteZAe1TPmfr8p6sy2VlP3vsIc7nZZ1hsT2cd6D6OMFChG/d96aoS+Rk4tHW2bYPHAPh8Jk+pfeI1IP89mkZ12L/wQOF7apKORdURmyfVB2U11zl1onyPjZE0rUynPmSRhsjZOjgQVH3FnuGF0dkXJhZjryZOablOO7L+ff1YfvsvcJ+G4iImuZJjdmFTCNTE5XjZ2jQPtPtDVKzFIX4JSmW8sOFJ1qO5jNDVz4URVEURSkr+vKhKIqiKEpZmXZmF8wKysP9Yuj1UKC0CUDsC0vcErnUyJfgcYmbu7QZR57PZ23NY4ZFVy79ep5ddhsdgeXlWdb9D6wcVBS9nIWKD4I7bZ59NwNulamUXHKvZF0QhGVqno0Vl2wJTE+lQoZzMLw6JiasZqanviPSbe9wjzWJoBsuT4RIRDRv3rzCNrqSchMWjo+2tjZRrqiwpoOmRnBZYyYkNANxF8eGBunWie0ZjA+ecptImk/Q9JZKy/EzOGC/23+yX9RVMvNaNCbbWlUp7wnvExeegxhf7pUr40Xc/GnrGtg+S4a5fmHby4XtN45KE1FPCnx4R2x/lUoBQJ4c21EwR2aYOTK2S2aD/X+X2JDTkbBcfu8/adt34IB01bz26ktE+YpLF9nzpcAEwuapdEqOXx/SF+TYvjjW+XFGwd85nZHPezrLluPT4FYZ48/s2HPo6ZChEORxQiE5L7zn0vcXtquqpekgm7NZiLe8/Lyo27b9RVF+5ZUdhe1qGL8t7Dl1Yd5ywI27ps2aS//k5j8Vdf391i348Z/8L1EXOW7b2pOU92BfVmZT3p+JF7aPgBl+kLlG5/Ly/syDsVb/7G/tvpAtvTFm+6AR0gP4JM8ZYPfIvIOw+mOhKx+KoiiKopQVfflQFEVRFKWs6MuHoiiKoihlZdppPnwIW8wyz5OfkzYrFzQOxDQg6PLJtQiuK+1bPrizylDsUoPCNSAeuK8GmYufwTDkEZkOuzZk7e1B0EmEHPbdIpGHPG6e2W+jYbDh11r30JOHZQrwegihHo1Yu2sG7JFch+MbWZcHO/R4E79Xgn129uy2MfYkOrRYurf1HLJl1HhceeWVotzcbFOSo37n+eetPXnXrl2iDjM7L1xotQBHj8q+7GGuttXV0kmNa0WGhqQ4Yn+3TMO+b5+17Z48cVLU8fHMj0lEVFdXJ8rcjfmKK64QdbMg1flY5yCS2pLTufeWoprZ+z/z8S5Rt/r9Fxe2d+6V17yXubYSEQ2etPXJYamXCbLUBqgb62iVWht+j555cZuoO9Bt7+XcuaKKdv9+a2G7c6Hsx/ZWma7gaK+193ugf+DPTD4L2hV4gPJM1+EGglBn71cKwrujbisStt8NheT4yYz3oT0NTsie4/yFC0TdsX6pYdr1B6vdiFXUiDqum0oMx0VdNi91FcGA7Z8kaIRyx+13h0aknog8Oed+/JILC9sXnHexqOMaqk118j4/uGdPYXvEkc9P1pfnCLIfsxjc6IaoHZMhCClhQOP11l77XMypqRN1AYf/dkmXc8/A7x7XF40zLcZE0JUPRVEURVHKir58KIqiKIpSVqad2SWL5gBmggi7YGaBFUuPLTlhxLZslkeIlHUY4ZRnvUXvXYe1J+LK7g2yqKZ5VzYuC9HufNceOD4qlwRbg/Y6s2npNuiGIbOlsW0NhWRdml0YmqgMmLfCLBIn3oMsi54YhE4PQN8VuUCOgYElwOKy7a+mJrnUWVVtTTats6WLLma53bFjx5h1b71lzR7Hjkl33hMnTohyZaV1Ud39+m5R9+QTTxa20U2Ou6+i2WXR4kWivHjR4sJ2OCSXzbmJJgXLy+iye+GFdgl5yflLRB13YUa3aDStcDA6bPtca+7a3/PWmN8jIorU2X0j4B4/l1upotKE9qGrV4pyJTMlYD+H2fgOoXs6mAZjzB1xzZekW+Xx4/a+Q1OpmruEQt+FHTnuXTY3eEZOIi5rT8SAWRfmrQCLSukVmYftOashUqvnQfgA5ncfARPwSI5lXn4HLpdxNr7TYJKORuXc1J+0psvdb2wRdUND1n3UcbFfwRWZubKPlJh7cGy7Ls6H9rj7u6WZdyRp543kKGRTZv1VFZK5ajGKcw2bnysi8vmOsXsShgi9GAYgyuYGDCDhsbnaR/difL5Z0Zl8q4uufCiKoiiKUl705UNRFEVRlLKiLx+KoiiKopSVaaf5QDc5rt0IgsYCpBtC84Fugw6zB54uBLgxzG0PXW2ZoQxMsJTPsSypoKkIQihr7jWXglC/Gaa5yBeJTsBOz9qDdnmX2Qrrm2RI8ABkOOQh1FEPwo/rgV01CIZx3xuf5gO1IXi/eMbOlhap6/jI1asL2w7cS8zMysuoueAhw1taWkTdiy/KMM7cLRdtp3PmzClsZyGMfX+/DW+ehfs8q1G6a15wwQWF7UhE2n27D9iMuKjx4CHTiYguvfTSMet4Jlt8DnD88HDeWJcB979SLF5q3Wsx1HmQPV+ZN2TW35oa+cw019tw56YoDPjYz0FRZmp2+xrg+Z5/Hj8OZne2xxkYlrb/ipi8X1xDVUoHBVKnIld1Xm3gOHIcomYKz2mPHAxJLULyiB2jlZEz/8kYGrTP13BGjtHhXHrMMmbcDoVsW30PrgvcV3nYhFKaJTeA850cPwcP2bH3wv/3jGwrC2He2yvd7Dsa7DNcFZPPWmWNdLsPs9+nWBD1gvy5wN8nM2YpB9mMeWgG7FfsHpf9lrgaXl1RFEVRlOmOvnwoiqIoilJW9OVDURRFUZSyMu00H2HwaQ4abtMDfQH4z/sl0k9zX+nT2YQ91FnwOm5rBufoQM62D1NjG/BXr62zIZ/7B2Va5DiznWZ9GdMB7fRB5q+exrTnzN5fZAGG11KuVfAgvDq/J9mUrMuBxiMLIfDHBv33ZW2Y2Z4bGmV47Lo6G44Z7zPXNBARZViclCzU8bgfw8My/fUIprtn2pHEsLxfXOsznIR7mbD3sqZWppPft1/Gxzh0xIb2jkak3qFzfmdhG/3+ueaESOpX0qDN4KHZeRhromK7ONctYdyIMHy3FA7TBeE5giz2QRXoU/b3yNgrR47beDjGl8eR4wm1EfJZ5NMISiN8FnYbreAOi+UxmoHYIUVaFnsclJzI+QauA0UgzpgFoXtxiq5ZHteweCKOMyDqUinbrxctkrFWimeOseH6HQfmPz8t+yubZZoZ2Dfk2PHtu6fR7/BUGPD7EAjykPIQESMsj9Ozf69te0rOBVzr01Apx2hrtdUhxYIQnyMsy3ywuTBX82fNgfQfODdyPU8+D8dh4eZRaoT6GS4CcYo0Qu8cXflQFEVRFKWsTOjl47777qNly5ZRTU0N1dTUUFdXF/3mN78p1KfTaVq7di01NjZSVVUV3XjjjdTX1zfpjVYURVEUZfoyIbNLe3s73X333bR48WIyxtCPf/xjuu6662jHjh100UUX0W233Ua//vWv6ZFHHqHa2lpat24d3XDDDUVuie8EDCfus6W0PCyrGTAPiKWrEm5X6NaJ8O8W7cuXxGDFNMhsGTkIUe5D+OUwC6+bhoyUqZRdKvccuVzpQXtiUbuMjqYCj7XVwFJeBswVPFw1Lm36bHnXheVcNHOMNzkiugIWh7i35zHozsuW3F1wWcNyNGrdCg2Y0xoarDkH3SHxMlJZe51o6kkm7bI1mm+42QPPgeY9PtYw3HFNlQ0JjlltMcMsN82hWy4H2xOJymXiADtuCF0DMaN0KfhzWeQSarc722eLurmzpfuzYZ1Syjphxp1b+VTw76Kbp91OJOR9roJ7EhH3RB7nTJ0aJ3JVeI5S3+UuvEHMl4AdXYKqajt+Aq7MWl1RKcdobdaa7dA9Pc86GuetAF4ZM4ngGI0w0yWa88MwjwVZ6AF0N65mz144JjPwBh27r1PUV+NPVyDukIOmJgx9wOdjeQ5P2GigDuYb8fyjSWYSmNDLxyc/+UlRvuuuu+i+++6jl156idrb2+n++++nhx56iD784Q8TEdEDDzxAF1xwAb300ktFqbsVRVEURZmZnLHmw/M8evjhh2lkZIS6urpo+/btlMvlaPVqG+BpyZIl1NHRQZs3bx7zOJlMhhKJhPhTFEVRFOXcZcIvH6+99hpVVVVRJBKhr33ta/Too4/ShRdeSL29vRQOh6murk7s39LSQr29vWMeb8OGDVRbW1v4mzt37oQvQlEURVGU6cOEXW3PP/982rlzJw0NDdHPf/5zWrNmDT333HNn3IDbb7+d1q9fXygnEomSLyA+2KVyzL5lAhBeHSyZpwubXvheCT0IUemw0gGW0t6gYd5nabTz6Gord3WD1gbpOvK6POZ6VlkrQ/Rm0tKG77Jw9P2D0oUux/qyAtI7Z0elCy/XLaA1kodMD0flcdClL5uVGpCxKNJYlHB/Lgobz+5zkesx2H35LULNB29DkR4DyiGmh8Dxw7UjCG/f6ULKc3CEclt30TjHdOGsjP3Bv4upAzDkPrH64mdr/DZiP2+vm4+zU7VBnKHIHZGF+R/32ScPYXuH3Aph6Ocwv67TzDdTjcHJiTOBtldVW41FNCzva7UH6RM8q6PA5zLMQo0HMb0FjEM+JnCM8vETgLoQzLl8jgmBhirI5mqC+Y77bRf/roDWh9X7oFfkExXKQVCr4bGQ6vm81J/lWdh4F7RyHjw1eXZPHBQwTgITfvkIh8O0aNEiIiJavnw5bd26lb7//e/T5z73OcpmsxSPx8XqR19fH7W2to5xtD/mqMA8FYqiKIqinLu84zgfvu9TJpOh5cuXUygUok2bNhXq9u7dS4cOHaKurq4SR1AURVEUZSYxoZWP22+/na699lrq6Oig4eFheuihh+jZZ5+lJ598kmpra+krX/kKrV+/nhoaGqimpoa+/vWvU1dXl3q6KIqiKIpSYEIvH8ePH6ebb76Zjh07RrW1tbRs2TJ68skn6SMf+QgREd1zzz3kui7deOONlMlk6JprrqEf/vCHk9tiHwxezFaHpsliv2pLKQ0B2sHRpsbt0GjHyzE7mQv+4CbHbIygT4lCWF7euiDsyzUWwYD0Tx+FMNejIzZ8dzIp03zHau05QxFpxwy50sbH41GgnTXPzwm20jCY1MwE4gJw0F7L9RAYB0DYcktoBrCeh/ImkjoKNNfmYUzwqyxKz832xRgTGNeCgxoQfl1FGotStu2isNtj7yv0Mhg3B9vO94VrHq++ioiootLGwMC4MBM5DteylOrXyQPnEHvOaLXUYuGcMna0kLOP02ngxkuEzTEhuK/Gl/NYqXPyMYH7FcfHGO8xYfw6sj2mxPPFYzuhxq108BWo5O1zUGPGdIZFkc7hA6HpktfBf3c80CXlS/y2FsVwnwQm9PJx//33l6yPRqO0ceNG2rhx4ztqlKIoiqIo5y6a20VRFEVRlLIy7bLaQoJDCrCyl8flJ1kUy2VF7kr2u4EAuM8WrdzzZS1prshnWCbJonPYpbNITJojgpWNopzL2fZEq6T7apC5qTno6gsmmuFR67oYCMpMo0HmspbJSpes+ioZJpibDjBkb0hE7JXvsznIYovLm2MxDJlhSwWfw6VWvsRdynRBJM03BlzouEkGTRDobsfHVqn2TGRZuFTbcd9S5iU8ZymzVKCk++zY7cX2FGUJLQH3dlPPt5kJjp9SLuilxl2p45Ycz0WP5djZcfGcwlriSlOGePZOk1uCm+2MgTQizJzv+2hyxTD/9hnOe3Je507oaDouOi7xZ1iz2iqKoiiKMs3Rlw9FURRFUcqKvnwoiqIoilJWpp3m4+LzFk11E6YVSxZPdQvOjN9uenKqm6CUie9+97tT3QSlDMQWtk11E951Sqs6xg+uCoRPudf0Rlc+FEVRFEUpK/ryoSiKoihKWdGXD0VRFEVRyoq+fCiKoiiKUlb05UNRFEVRlLJy1nm7vB0RDhNMKYqiKIpy9vL273apSM5v45jx7FVGDh8+THPnzp3qZiiKoiiKcgb09PRQe3t7yX3OupcP3/fp6NGjZIyhjo4O6unpoZqamtN/cYaRSCRo7ty52j9joP1TGu2f0mj/lEb7Z2xmct8YY2h4eJja2tpOmxvqrDO7uK5L7e3thURiNTU1M+4GTgTtn9Jo/5RG+6c02j+l0f4Zm5naN7W1tePaTwWniqIoiqKUFX35UBRFURSlrJy1Lx+RSIT+5m/+hiKRyFQ35axE+6c02j+l0f4pjfZPabR/xkb7ZnycdYJTRVEURVHObc7alQ9FURRFUc5N9OVDURRFUZSyoi8fiqIoiqKUFX35UBRFURSlrOjLh6IoiqIoZeWsffnYuHEjzZ8/n6LRKK1atYpefvnlqW5S2dmwYQNdfvnlVF1dTc3NzXT99dfT3r17xT7pdJrWrl1LjY2NVFVVRTfeeCP19fVNUYunlrvvvpscx6Fbb7218NlM758jR47Qn/zJn1BjYyPFYjFaunQpbdu2rVBvjKE777yTZs+eTbFYjFavXk379u2bwhaXD8/z6I477qDOzk6KxWK0cOFC+ru/+zuRFGsm9c/zzz9Pn/zkJ6mtrY0cx6HHHntM1I+nLwYGBuimm26impoaqquro6985SuUTCbLeBXvHqX6J5fL0Te/+U1aunQpVVZWUltbG91888109OhRcYxzuX8mjDkLefjhh004HDb//u//bv7whz+YP/uzPzN1dXWmr69vqptWVq655hrzwAMPmF27dpmdO3eaj3/846ajo8Mkk8nCPl/72tfM3LlzzaZNm8y2bdvMFVdcYa688sopbPXU8PLLL5v58+ebZcuWmVtuuaXw+Uzun4GBATNv3jzzxS9+0WzZssXs37/fPPnkk+bNN98s7HP33Xeb2tpa89hjj5lXX33VfOpTnzKdnZ0mlUpNYcvLw1133WUaGxvN448/brq7u80jjzxiqqqqzPe///3CPjOpf/7nf/7HfOc73zG/+MUvDBGZRx99VNSPpy8+9rGPmUsuucS89NJL5ne/+51ZtGiR+cIXvlDmK3l3KNU/8XjcrF692vzsZz8ze/bsMZs3bzYrV640y5cvF8c4l/tnopyVLx8rV640a9euLZQ9zzNtbW1mw4YNU9iqqef48eOGiMxzzz1njPnjgA+FQuaRRx4p7PP6668bIjKbN2+eqmaWneHhYbN48WLz1FNPmQ984AOFl4+Z3j/f/OY3zXvf+94x633fN62treaf/umfCp/F43ETiUTMf/7nf5ajiVPKJz7xCfPlL39ZfHbDDTeYm266yRgzs/sHf1zH0xe7d+82RGS2bt1a2Oc3v/mNcRzHHDlypGxtLwenejlDXn75ZUNE5uDBg8aYmdU/4+GsM7tks1navn07rV69uvCZ67q0evVq2rx58xS2bOoZGhoiIqKGhgYiItq+fTvlcjnRV0uWLKGOjo4Z1Vdr166lT3ziE6IfiLR//vu//5tWrFhBn/nMZ6i5uZkuu+wy+rd/+7dCfXd3N/X29or+qa2tpVWrVs2I/rnyyitp06ZN9MYbbxAR0auvvkovvPACXXvttUSk/cMZT19s3ryZ6urqaMWKFYV9Vq9eTa7r0pYtW8re5qlmaGiIHMehuro6ItL+Qc66rLYnT54kz/OopaVFfN7S0kJ79uyZolZNPb7v06233kpXXXUVXXzxxURE1NvbS+FwuDC436alpYV6e3unoJXl5+GHH6ZXXnmFtm7dWlQ30/tn//79dN9999H69evp29/+Nm3dupX+8i//ksLhMK1Zs6bQB6d61mZC/3zrW9+iRCJBS5YsoUAgQJ7n0V133UU33XQTEdGM7x/OePqit7eXmpubRX0wGKSGhoYZ11/pdJq++c1v0he+8IVCZlvtH8lZ9/KhnJq1a9fSrl276IUXXpjqppw19PT00C233EJPPfUURaPRqW7OWYfv+7RixQr6h3/4ByIiuuyyy2jXrl30ox/9iNasWTPFrZt6/uu//ot++tOf0kMPPUQXXXQR7dy5k2699VZqa2vT/lHOmFwuR5/97GfJGEP33XffVDfnrOWsM7s0NTVRIBAo8kjo6+uj1tbWKWrV1LJu3Tp6/PHH6ZlnnqH29vbC562trZTNZikej4v9Z0pfbd++nY4fP07vec97KBgMUjAYpOeee45+8IMfUDAYpJaWlhndP7Nnz6YLL7xQfHbBBRfQoUOHiIgKfTBTn7W/+qu/om9961v0+c9/npYuXUp/+qd/Srfddhtt2LCBiLR/OOPpi9bWVjp+/Lioz+fzNDAwMGP66+0Xj4MHD9JTTz1VWPUg0v5BzrqXj3A4TMuXL6dNmzYVPvN9nzZt2kRdXV1T2LLyY4yhdevW0aOPPkpPP/00dXZ2ivrly5dTKBQSfbV37146dOjQjOirq6++ml577TXauXNn4W/FihV00003FbZncv9cddVVRa7Zb7zxBs2bN4+IiDo7O6m1tVX0TyKRoC1btsyI/hkdHSXXlVNgIBAg3/eJSPuHM56+6Orqong8Ttu3by/s8/TTT5Pv+7Rq1aqyt7ncvP3isW/fPvrtb39LjY2Non6m908RU614PRUPP/ywiUQi5sEHHzS7d+82X/3qV01dXZ3p7e2d6qaVlT//8z83tbW15tlnnzXHjh0r/I2Ojhb2+drXvmY6OjrM008/bbZt22a6urpMV1fXFLZ6auHeLsbM7P55+eWXTTAYNHfddZfZt2+f+elPf2oqKirMT37yk8I+d999t6mrqzO//OUvze9//3tz3XXXnbOupMiaNWvMnDlzCq62v/jFL0xTU5P5xje+UdhnJvXP8PCw2bFjh9mxY4chIvPP//zPZseOHQVvjfH0xcc+9jFz2WWXmS1btpgXXnjBLF68+JxxJS3VP9ls1nzqU58y7e3tZufOnWK+zmQyhWOcy/0zUc7Klw9jjPmXf/kX09HRYcLhsFm5cqV56aWXprpJZYeITvn3wAMPFPZJpVLmL/7iL0x9fb2pqKgwn/70p82xY8emrtFTDL58zPT++dWvfmUuvvhiE4lEzJIlS8y//uu/inrf980dd9xhWlpaTCQSMVdffbXZu3fvFLW2vCQSCXPLLbeYjo4OE41GzYIFC8x3vvMd8WMxk/rnmWeeOeV8s2bNGmPM+Pqiv7/ffOELXzBVVVWmpqbGfOlLXzLDw8NTcDWTT6n+6e7uHnO+fuaZZwrHOJf7Z6I4xrBwfoqiKIqiKO8yZ53mQ1EURVGUcxt9+VAURVEUpazoy4eiKIqiKGVFXz4URVEURSkr+vKhKIqiKEpZ0ZcPRVEURVHKir58KIqiKIpSVvTlQ1EURVGUsqIvH4qiKIqilBV9+VAURVEUpazoy4eiKIqiKGXl/wcqe943/xZrZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def random_aug(image):\n",
    "    augmentations =[\"colorjitter\", \"randomhorizontalflip\", \"randomcrop\", \"randomgrayscale\"]\n",
    "\n",
    "    augmentation = np.random.choice(augmentations)\n",
    "\n",
    "    if augmentation == \"randomhorizontalflip\":\n",
    "        transform = transforms.RandomHorizontalFlip(1)\n",
    "    elif augmentation == \"randomcrop\":\n",
    "        transform = transforms.RandomCrop(20)\n",
    "    elif augmentation == \"randomgrayscale\":\n",
    "        transform = transforms.RandomGrayscale(0.2)\n",
    "    elif augmentation == \"colorjitter\":\n",
    "        transform = transforms.RandomApply([transforms.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8)\n",
    "\n",
    "    augmented_img = transform(image)\n",
    "    return augmented_img\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# random augmentation\n",
    "flipped_images = random_aug(images)\n",
    "imshow(torchvision.utils.make_grid(flipped_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classification accuracy:\n",
    "def knn_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = SimSiam()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss() # Got our own loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m#loss = criterion(outputs, labels)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m loss \u001b[39m=\u001b[39m D(p1, z2)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m D(p2, z1)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):            \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs, labels = data\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # random augmentations:\n",
    "        x1 = random_aug(images)\n",
    "        x2 = random_aug(images)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        z1, p1 = model(x1)\n",
    "        z2, p2 = model(x2)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss = D(p1, z2)/2 + D(p2, z1)/2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current accuracy:  0.0\n",
      "current accuracy:  0.375\n",
      "current accuracy:  0.25\n",
      "current accuracy:  0.1875\n",
      "current accuracy:  0.15\n",
      "current accuracy:  0.125\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.09375\n",
      "current accuracy:  0.08333333333333333\n",
      "current accuracy:  0.075\n",
      "current accuracy:  0.06818181818181818\n",
      "current accuracy:  0.0625\n",
      "current accuracy:  0.057692307692307696\n",
      "current accuracy:  0.05357142857142857\n",
      "current accuracy:  0.05\n",
      "current accuracy:  0.078125\n",
      "current accuracy:  0.07352941176470588\n",
      "current accuracy:  0.06944444444444445\n",
      "current accuracy:  0.06578947368421052\n",
      "current accuracy:  0.0875\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.125\n",
      "current accuracy:  0.11956521739130435\n",
      "current accuracy:  0.11458333333333333\n",
      "current accuracy:  0.13\n",
      "current accuracy:  0.125\n",
      "current accuracy:  0.1388888888888889\n",
      "current accuracy:  0.13392857142857142\n",
      "current accuracy:  0.12931034482758622\n",
      "current accuracy:  0.125\n",
      "current accuracy:  0.12096774193548387\n",
      "current accuracy:  0.1171875\n",
      "current accuracy:  0.11363636363636363\n",
      "current accuracy:  0.11029411764705882\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10416666666666667\n",
      "current accuracy:  0.10135135135135136\n",
      "current accuracy:  0.09868421052631579\n",
      "current accuracy:  0.10897435897435898\n",
      "current accuracy:  0.10625\n",
      "current accuracy:  0.10365853658536585\n",
      "current accuracy:  0.10119047619047619\n",
      "current accuracy:  0.09883720930232558\n",
      "current accuracy:  0.11363636363636363\n",
      "current accuracy:  0.1111111111111111\n",
      "current accuracy:  0.10869565217391304\n",
      "current accuracy:  0.11702127659574468\n",
      "current accuracy:  0.11458333333333333\n",
      "current accuracy:  0.11224489795918367\n",
      "current accuracy:  0.125\n",
      "current accuracy:  0.12254901960784313\n",
      "current accuracy:  0.1201923076923077\n",
      "current accuracy:  0.1179245283018868\n",
      "current accuracy:  0.11574074074074074\n",
      "current accuracy:  0.11363636363636363\n",
      "current accuracy:  0.11160714285714286\n",
      "current accuracy:  0.10964912280701754\n",
      "current accuracy:  0.10775862068965517\n",
      "current accuracy:  0.1059322033898305\n",
      "current accuracy:  0.10416666666666667\n",
      "current accuracy:  0.11065573770491803\n",
      "current accuracy:  0.10887096774193548\n",
      "current accuracy:  0.11507936507936507\n",
      "current accuracy:  0.11328125\n",
      "current accuracy:  0.11923076923076924\n",
      "current accuracy:  0.11742424242424243\n",
      "current accuracy:  0.11567164179104478\n",
      "current accuracy:  0.11397058823529412\n",
      "current accuracy:  0.11231884057971014\n",
      "current accuracy:  0.11071428571428571\n",
      "current accuracy:  0.10915492957746478\n",
      "current accuracy:  0.11458333333333333\n",
      "current accuracy:  0.11301369863013698\n",
      "current accuracy:  0.11148648648648649\n",
      "current accuracy:  0.11\n",
      "current accuracy:  0.10855263157894737\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10576923076923077\n",
      "current accuracy:  0.11075949367088607\n",
      "current accuracy:  0.109375\n",
      "current accuracy:  0.10802469135802469\n",
      "current accuracy:  0.10670731707317073\n",
      "current accuracy:  0.10542168674698796\n",
      "current accuracy:  0.10416666666666667\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.10755813953488372\n",
      "current accuracy:  0.10632183908045977\n",
      "current accuracy:  0.10511363636363637\n",
      "current accuracy:  0.10393258426966293\n",
      "current accuracy:  0.10277777777777777\n",
      "current accuracy:  0.10164835164835165\n",
      "current accuracy:  0.10054347826086957\n",
      "current accuracy:  0.09946236559139784\n",
      "current accuracy:  0.09840425531914894\n",
      "current accuracy:  0.10263157894736842\n",
      "current accuracy:  0.1015625\n",
      "current accuracy:  0.1056701030927835\n",
      "current accuracy:  0.10459183673469388\n",
      "current accuracy:  0.10353535353535354\n",
      "current accuracy:  0.1025\n",
      "current accuracy:  0.10148514851485149\n",
      "current accuracy:  0.10049019607843138\n",
      "current accuracy:  0.09951456310679611\n",
      "current accuracy:  0.0985576923076923\n",
      "current accuracy:  0.09761904761904762\n",
      "current accuracy:  0.10141509433962265\n",
      "current accuracy:  0.10046728971962617\n",
      "current accuracy:  0.09953703703703703\n",
      "current accuracy:  0.09862385321100918\n",
      "current accuracy:  0.09772727272727273\n",
      "current accuracy:  0.09684684684684684\n",
      "current accuracy:  0.09598214285714286\n",
      "current accuracy:  0.10176991150442478\n",
      "current accuracy:  0.10087719298245613\n",
      "current accuracy:  0.1\n",
      "current accuracy:  0.09913793103448276\n",
      "current accuracy:  0.09829059829059829\n",
      "current accuracy:  0.09745762711864407\n",
      "current accuracy:  0.09663865546218488\n",
      "current accuracy:  0.09583333333333334\n",
      "current accuracy:  0.09504132231404959\n",
      "current accuracy:  0.10040983606557377\n",
      "current accuracy:  0.10365853658536585\n",
      "current accuracy:  0.1028225806451613\n",
      "current accuracy:  0.102\n",
      "current accuracy:  0.10515873015873016\n",
      "current accuracy:  0.10433070866141732\n",
      "current accuracy:  0.103515625\n",
      "current accuracy:  0.10271317829457365\n",
      "current accuracy:  0.10192307692307692\n",
      "current accuracy:  0.10114503816793893\n",
      "current accuracy:  0.10606060606060606\n",
      "current accuracy:  0.10526315789473684\n",
      "current accuracy:  0.1044776119402985\n",
      "current accuracy:  0.1037037037037037\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.10218978102189781\n",
      "current accuracy:  0.1068840579710145\n",
      "current accuracy:  0.10611510791366907\n",
      "current accuracy:  0.10535714285714286\n",
      "current accuracy:  0.10460992907801418\n",
      "current accuracy:  0.10387323943661972\n",
      "current accuracy:  0.10314685314685315\n",
      "current accuracy:  0.10243055555555555\n",
      "current accuracy:  0.10172413793103448\n",
      "current accuracy:  0.10102739726027397\n",
      "current accuracy:  0.10034013605442177\n",
      "current accuracy:  0.09966216216216216\n",
      "current accuracy:  0.09899328859060402\n",
      "current accuracy:  0.10166666666666667\n",
      "current accuracy:  0.10099337748344371\n",
      "current accuracy:  0.10032894736842106\n",
      "current accuracy:  0.09967320261437909\n",
      "current accuracy:  0.1038961038961039\n",
      "current accuracy:  0.1032258064516129\n",
      "current accuracy:  0.10256410256410256\n",
      "current accuracy:  0.10191082802547771\n",
      "current accuracy:  0.10126582278481013\n",
      "current accuracy:  0.10377358490566038\n",
      "current accuracy:  0.103125\n",
      "current accuracy:  0.10248447204968944\n",
      "current accuracy:  0.10185185185185185\n",
      "current accuracy:  0.10122699386503067\n",
      "current accuracy:  0.10060975609756098\n",
      "current accuracy:  0.10454545454545454\n",
      "current accuracy:  0.10391566265060241\n",
      "current accuracy:  0.10329341317365269\n",
      "current accuracy:  0.10267857142857142\n",
      "current accuracy:  0.10207100591715976\n",
      "current accuracy:  0.10147058823529412\n",
      "current accuracy:  0.10087719298245613\n",
      "current accuracy:  0.1002906976744186\n",
      "current accuracy:  0.09971098265895954\n",
      "current accuracy:  0.09913793103448276\n",
      "current accuracy:  0.09857142857142857\n",
      "current accuracy:  0.09801136363636363\n",
      "current accuracy:  0.09745762711864407\n",
      "current accuracy:  0.10112359550561797\n",
      "current accuracy:  0.1005586592178771\n",
      "current accuracy:  0.1\n",
      "current accuracy:  0.09944751381215469\n",
      "current accuracy:  0.0989010989010989\n",
      "current accuracy:  0.09836065573770492\n",
      "current accuracy:  0.09782608695652174\n",
      "current accuracy:  0.1\n",
      "current accuracy:  0.09946236559139784\n",
      "current accuracy:  0.10160427807486631\n",
      "current accuracy:  0.10372340425531915\n",
      "current accuracy:  0.10317460317460317\n",
      "current accuracy:  0.10263157894736842\n",
      "current accuracy:  0.10209424083769633\n",
      "current accuracy:  0.1015625\n",
      "current accuracy:  0.10103626943005181\n",
      "current accuracy:  0.10051546391752578\n",
      "current accuracy:  0.1\n",
      "current accuracy:  0.09948979591836735\n",
      "current accuracy:  0.09898477157360407\n",
      "current accuracy:  0.09848484848484848\n",
      "current accuracy:  0.09798994974874371\n",
      "current accuracy:  0.0975\n",
      "current accuracy:  0.09701492537313433\n",
      "current accuracy:  0.10024752475247525\n",
      "current accuracy:  0.09975369458128079\n",
      "current accuracy:  0.09926470588235294\n",
      "current accuracy:  0.09878048780487805\n",
      "current accuracy:  0.0983009708737864\n",
      "current accuracy:  0.09782608695652174\n",
      "current accuracy:  0.09735576923076923\n",
      "current accuracy:  0.09928229665071771\n",
      "current accuracy:  0.0988095238095238\n",
      "current accuracy:  0.09834123222748815\n",
      "current accuracy:  0.09787735849056604\n",
      "current accuracy:  0.09741784037558686\n",
      "current accuracy:  0.0969626168224299\n",
      "current accuracy:  0.09651162790697675\n",
      "current accuracy:  0.09837962962962964\n",
      "current accuracy:  0.097926267281106\n",
      "current accuracy:  0.09747706422018348\n",
      "current accuracy:  0.09703196347031963\n",
      "current accuracy:  0.09659090909090909\n",
      "current accuracy:  0.09615384615384616\n",
      "current accuracy:  0.09797297297297297\n",
      "current accuracy:  0.09753363228699552\n",
      "current accuracy:  0.09933035714285714\n",
      "current accuracy:  0.10111111111111111\n",
      "current accuracy:  0.1006637168141593\n",
      "current accuracy:  0.10022026431718062\n",
      "current accuracy:  0.09978070175438597\n",
      "current accuracy:  0.10152838427947598\n",
      "current accuracy:  0.10108695652173913\n",
      "current accuracy:  0.1038961038961039\n",
      "current accuracy:  0.10560344827586207\n",
      "current accuracy:  0.1072961373390558\n",
      "current accuracy:  0.10897435897435898\n",
      "current accuracy:  0.10851063829787234\n",
      "current accuracy:  0.10805084745762712\n",
      "current accuracy:  0.10970464135021098\n",
      "current accuracy:  0.11134453781512606\n",
      "current accuracy:  0.1108786610878661\n",
      "current accuracy:  0.11041666666666666\n",
      "current accuracy:  0.11203319502074689\n",
      "current accuracy:  0.11466942148760331\n",
      "current accuracy:  0.11419753086419752\n",
      "current accuracy:  0.11372950819672131\n",
      "current accuracy:  0.11326530612244898\n",
      "current accuracy:  0.11280487804878049\n",
      "current accuracy:  0.11234817813765183\n",
      "current accuracy:  0.11189516129032258\n",
      "current accuracy:  0.11144578313253012\n",
      "current accuracy:  0.111\n",
      "current accuracy:  0.11055776892430279\n",
      "current accuracy:  0.11011904761904762\n",
      "current accuracy:  0.10968379446640317\n",
      "current accuracy:  0.10925196850393701\n",
      "current accuracy:  0.10882352941176471\n",
      "current accuracy:  0.1083984375\n",
      "current accuracy:  0.10992217898832685\n",
      "current accuracy:  0.10949612403100775\n",
      "current accuracy:  0.11196911196911197\n",
      "current accuracy:  0.11153846153846154\n",
      "current accuracy:  0.1111111111111111\n",
      "current accuracy:  0.11068702290076336\n",
      "current accuracy:  0.11026615969581749\n",
      "current accuracy:  0.10984848484848485\n",
      "current accuracy:  0.10943396226415095\n",
      "current accuracy:  0.10902255639097744\n",
      "current accuracy:  0.10861423220973783\n",
      "current accuracy:  0.10820895522388059\n",
      "current accuracy:  0.10780669144981413\n",
      "current accuracy:  0.11018518518518519\n",
      "current accuracy:  0.10977859778597786\n",
      "current accuracy:  0.11121323529411764\n",
      "current accuracy:  0.1108058608058608\n",
      "current accuracy:  0.1104014598540146\n",
      "current accuracy:  0.11\n",
      "current accuracy:  0.10960144927536232\n",
      "current accuracy:  0.1092057761732852\n",
      "current accuracy:  0.10881294964028777\n",
      "current accuracy:  0.10842293906810035\n",
      "current accuracy:  0.10803571428571429\n",
      "current accuracy:  0.1094306049822064\n",
      "current accuracy:  0.10904255319148937\n",
      "current accuracy:  0.10865724381625441\n",
      "current accuracy:  0.10827464788732394\n",
      "current accuracy:  0.10789473684210527\n",
      "current accuracy:  0.10751748251748251\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.109375\n",
      "current accuracy:  0.10899653979238755\n",
      "current accuracy:  0.1103448275862069\n",
      "current accuracy:  0.10996563573883161\n",
      "current accuracy:  0.1095890410958904\n",
      "current accuracy:  0.10921501706484642\n",
      "current accuracy:  0.10884353741496598\n",
      "current accuracy:  0.10847457627118644\n",
      "current accuracy:  0.10810810810810811\n",
      "current accuracy:  0.10942760942760943\n",
      "current accuracy:  0.10906040268456375\n",
      "current accuracy:  0.10869565217391304\n",
      "current accuracy:  0.10833333333333334\n",
      "current accuracy:  0.1079734219269103\n",
      "current accuracy:  0.1076158940397351\n",
      "current accuracy:  0.10726072607260725\n",
      "current accuracy:  0.1069078947368421\n",
      "current accuracy:  0.10655737704918032\n",
      "current accuracy:  0.10866013071895425\n",
      "current accuracy:  0.10830618892508144\n",
      "current accuracy:  0.10795454545454546\n",
      "current accuracy:  0.10922330097087378\n",
      "current accuracy:  0.10887096774193548\n",
      "current accuracy:  0.1085209003215434\n",
      "current accuracy:  0.10817307692307693\n",
      "current accuracy:  0.10942492012779553\n",
      "current accuracy:  0.10907643312101911\n",
      "current accuracy:  0.10873015873015873\n",
      "current accuracy:  0.10838607594936708\n",
      "current accuracy:  0.10804416403785488\n",
      "current accuracy:  0.10770440251572327\n",
      "current accuracy:  0.10893416927899686\n",
      "current accuracy:  0.11015625\n",
      "current accuracy:  0.10981308411214953\n",
      "current accuracy:  0.10947204968944099\n",
      "current accuracy:  0.10913312693498452\n",
      "current accuracy:  0.1087962962962963\n",
      "current accuracy:  0.10846153846153846\n",
      "current accuracy:  0.10812883435582822\n",
      "current accuracy:  0.10779816513761468\n",
      "current accuracy:  0.10746951219512195\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10681818181818181\n",
      "current accuracy:  0.10800604229607251\n",
      "current accuracy:  0.10768072289156627\n",
      "current accuracy:  0.10735735735735735\n",
      "current accuracy:  0.10853293413173652\n",
      "current accuracy:  0.10820895522388059\n",
      "current accuracy:  0.10788690476190477\n",
      "current accuracy:  0.10756676557863501\n",
      "current accuracy:  0.10724852071005918\n",
      "current accuracy:  0.10693215339233038\n",
      "current accuracy:  0.10661764705882353\n",
      "current accuracy:  0.1063049853372434\n",
      "current accuracy:  0.10599415204678363\n",
      "current accuracy:  0.10568513119533528\n",
      "current accuracy:  0.10537790697674419\n",
      "current accuracy:  0.10507246376811594\n",
      "current accuracy:  0.10476878612716763\n",
      "current accuracy:  0.10446685878962536\n",
      "current accuracy:  0.10560344827586207\n",
      "current accuracy:  0.10530085959885387\n",
      "current accuracy:  0.105\n",
      "current accuracy:  0.1047008547008547\n",
      "current accuracy:  0.10582386363636363\n",
      "current accuracy:  0.10552407932011332\n",
      "current accuracy:  0.10734463276836158\n",
      "current accuracy:  0.10704225352112676\n",
      "current accuracy:  0.10814606741573034\n",
      "current accuracy:  0.10784313725490197\n",
      "current accuracy:  0.10754189944134078\n",
      "current accuracy:  0.10724233983286909\n",
      "current accuracy:  0.10694444444444444\n",
      "current accuracy:  0.10664819944598337\n",
      "current accuracy:  0.106353591160221\n",
      "current accuracy:  0.10743801652892562\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10821917808219178\n",
      "current accuracy:  0.1092896174863388\n",
      "current accuracy:  0.11035422343324251\n",
      "current accuracy:  0.11005434782608696\n",
      "current accuracy:  0.10975609756097561\n",
      "current accuracy:  0.11148648648648649\n",
      "current accuracy:  0.11118598382749326\n",
      "current accuracy:  0.11088709677419355\n",
      "current accuracy:  0.11058981233243968\n",
      "current accuracy:  0.11029411764705882\n",
      "current accuracy:  0.11\n",
      "current accuracy:  0.10970744680851063\n",
      "current accuracy:  0.10941644562334217\n",
      "current accuracy:  0.10912698412698413\n",
      "current accuracy:  0.10883905013192612\n",
      "current accuracy:  0.10855263157894737\n",
      "current accuracy:  0.10826771653543307\n",
      "current accuracy:  0.10929319371727748\n",
      "current accuracy:  0.10900783289817233\n",
      "current accuracy:  0.11067708333333333\n",
      "current accuracy:  0.11038961038961038\n",
      "current accuracy:  0.11010362694300518\n",
      "current accuracy:  0.10981912144702842\n",
      "current accuracy:  0.1095360824742268\n",
      "current accuracy:  0.10925449871465295\n",
      "current accuracy:  0.10897435897435898\n",
      "current accuracy:  0.10869565217391304\n",
      "current accuracy:  0.10841836734693877\n",
      "current accuracy:  0.10814249363867684\n",
      "current accuracy:  0.10913705583756345\n",
      "current accuracy:  0.10886075949367088\n",
      "current accuracy:  0.10858585858585859\n",
      "current accuracy:  0.10831234256926953\n",
      "current accuracy:  0.10804020100502512\n",
      "current accuracy:  0.10964912280701754\n",
      "current accuracy:  0.109375\n",
      "current accuracy:  0.10910224438902744\n",
      "current accuracy:  0.11069651741293532\n",
      "current accuracy:  0.11042183622828784\n",
      "current accuracy:  0.11014851485148515\n",
      "current accuracy:  0.10987654320987654\n",
      "current accuracy:  0.10960591133004927\n",
      "current accuracy:  0.10933660933660934\n",
      "current accuracy:  0.1090686274509804\n",
      "current accuracy:  0.10880195599022005\n",
      "current accuracy:  0.10853658536585366\n",
      "current accuracy:  0.10827250608272507\n",
      "current accuracy:  0.10800970873786407\n",
      "current accuracy:  0.10774818401937046\n",
      "current accuracy:  0.10748792270531402\n",
      "current accuracy:  0.10722891566265061\n",
      "current accuracy:  0.10697115384615384\n",
      "current accuracy:  0.10851318944844125\n",
      "current accuracy:  0.10944976076555024\n",
      "current accuracy:  0.10918854415274463\n",
      "current accuracy:  0.10892857142857143\n",
      "current accuracy:  0.10866983372921615\n",
      "current accuracy:  0.10841232227488151\n",
      "current accuracy:  0.10815602836879433\n",
      "current accuracy:  0.10790094339622641\n",
      "current accuracy:  0.10764705882352942\n",
      "current accuracy:  0.10915492957746478\n",
      "current accuracy:  0.10889929742388758\n",
      "current accuracy:  0.10864485981308411\n",
      "current accuracy:  0.10955710955710955\n",
      "current accuracy:  0.11046511627906977\n",
      "current accuracy:  0.11020881670533643\n",
      "current accuracy:  0.1111111111111111\n",
      "current accuracy:  0.11085450346420324\n",
      "current accuracy:  0.11059907834101383\n",
      "current accuracy:  0.1103448275862069\n",
      "current accuracy:  0.11123853211009174\n",
      "current accuracy:  0.11098398169336385\n",
      "current accuracy:  0.11073059360730593\n",
      "current accuracy:  0.11047835990888383\n",
      "current accuracy:  0.11136363636363636\n",
      "current accuracy:  0.1111111111111111\n",
      "current accuracy:  0.11085972850678733\n",
      "current accuracy:  0.11060948081264109\n",
      "current accuracy:  0.11036036036036036\n",
      "current accuracy:  0.1101123595505618\n",
      "current accuracy:  0.10986547085201794\n",
      "current accuracy:  0.10961968680089486\n",
      "current accuracy:  0.109375\n",
      "current accuracy:  0.1091314031180401\n",
      "current accuracy:  0.10888888888888888\n",
      "current accuracy:  0.10864745011086474\n",
      "current accuracy:  0.1084070796460177\n",
      "current accuracy:  0.10927152317880795\n",
      "current accuracy:  0.10903083700440529\n",
      "current accuracy:  0.1087912087912088\n",
      "current accuracy:  0.10855263157894737\n",
      "current accuracy:  0.10831509846827134\n",
      "current accuracy:  0.10807860262008734\n",
      "current accuracy:  0.10784313725490197\n",
      "current accuracy:  0.10760869565217392\n",
      "current accuracy:  0.10737527114967461\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10691144708423327\n",
      "current accuracy:  0.10668103448275862\n",
      "current accuracy:  0.1064516129032258\n",
      "current accuracy:  0.10622317596566523\n",
      "current accuracy:  0.10599571734475374\n",
      "current accuracy:  0.10683760683760683\n",
      "current accuracy:  0.10660980810234541\n",
      "current accuracy:  0.10638297872340426\n",
      "current accuracy:  0.10721868365180467\n",
      "current accuracy:  0.10699152542372882\n",
      "current accuracy:  0.10676532769556026\n",
      "current accuracy:  0.10654008438818566\n",
      "current accuracy:  0.10631578947368421\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10796645702306079\n",
      "current accuracy:  0.10774058577405858\n",
      "current accuracy:  0.10908141962421712\n",
      "current accuracy:  0.10885416666666667\n",
      "current accuracy:  0.10862785862785863\n",
      "current accuracy:  0.10840248962655602\n",
      "current accuracy:  0.10817805383022774\n",
      "current accuracy:  0.10795454545454546\n",
      "current accuracy:  0.1077319587628866\n",
      "current accuracy:  0.10751028806584362\n",
      "current accuracy:  0.10728952772073921\n",
      "current accuracy:  0.10706967213114754\n",
      "current accuracy:  0.10685071574642127\n",
      "current accuracy:  0.10663265306122449\n",
      "current accuracy:  0.10743380855397149\n",
      "current accuracy:  0.10721544715447154\n",
      "current accuracy:  0.10801217038539554\n",
      "current accuracy:  0.10931174089068826\n",
      "current accuracy:  0.10909090909090909\n",
      "current accuracy:  0.10887096774193548\n",
      "current accuracy:  0.10865191146881288\n",
      "current accuracy:  0.10843373493975904\n",
      "current accuracy:  0.10821643286573146\n",
      "current accuracy:  0.108\n",
      "current accuracy:  0.10778443113772455\n",
      "current accuracy:  0.10756972111553785\n",
      "current accuracy:  0.1073558648111332\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10693069306930693\n",
      "current accuracy:  0.10770750988142293\n",
      "current accuracy:  0.10749506903353057\n",
      "current accuracy:  0.10728346456692914\n",
      "current accuracy:  0.10707269155206287\n",
      "current accuracy:  0.10686274509803921\n",
      "current accuracy:  0.10763209393346379\n",
      "current accuracy:  0.107421875\n",
      "current accuracy:  0.10721247563352826\n",
      "current accuracy:  0.10700389105058365\n",
      "current accuracy:  0.10679611650485436\n",
      "current accuracy:  0.1065891472868217\n",
      "current accuracy:  0.10735009671179883\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10789980732177264\n",
      "current accuracy:  0.10865384615384616\n",
      "current accuracy:  0.10844529750479846\n",
      "current accuracy:  0.10919540229885058\n",
      "current accuracy:  0.1089866156787763\n",
      "current accuracy:  0.10877862595419847\n",
      "current accuracy:  0.10857142857142857\n",
      "current accuracy:  0.10836501901140684\n",
      "current accuracy:  0.10815939278937381\n",
      "current accuracy:  0.10890151515151515\n",
      "current accuracy:  0.10869565217391304\n",
      "current accuracy:  0.10849056603773585\n",
      "current accuracy:  0.10828625235404897\n",
      "current accuracy:  0.1080827067669173\n",
      "current accuracy:  0.10787992495309569\n",
      "current accuracy:  0.10767790262172285\n",
      "current accuracy:  0.10747663551401869\n",
      "current accuracy:  0.10727611940298508\n",
      "current accuracy:  0.10707635009310987\n",
      "current accuracy:  0.10687732342007435\n",
      "current accuracy:  0.10667903525046382\n",
      "current accuracy:  0.10648148148148148\n",
      "current accuracy:  0.10628465804066543\n",
      "current accuracy:  0.10608856088560886\n",
      "current accuracy:  0.10681399631675875\n",
      "current accuracy:  0.10753676470588236\n",
      "current accuracy:  0.10825688073394496\n",
      "current accuracy:  0.10943223443223443\n",
      "current accuracy:  0.10923217550274222\n",
      "current accuracy:  0.10903284671532847\n",
      "current accuracy:  0.10883424408014572\n",
      "current accuracy:  0.10863636363636364\n",
      "current accuracy:  0.10843920145190562\n",
      "current accuracy:  0.1082427536231884\n",
      "current accuracy:  0.10804701627486438\n",
      "current accuracy:  0.1078519855595668\n",
      "current accuracy:  0.10765765765765765\n",
      "current accuracy:  0.10746402877697842\n",
      "current accuracy:  0.10727109515260323\n",
      "current accuracy:  0.10797491039426524\n",
      "current accuracy:  0.10778175313059034\n",
      "current accuracy:  0.10758928571428572\n",
      "current accuracy:  0.10739750445632798\n",
      "current accuracy:  0.10720640569395018\n",
      "current accuracy:  0.10790408525754884\n",
      "current accuracy:  0.1077127659574468\n",
      "current accuracy:  0.1075221238938053\n",
      "current accuracy:  0.1073321554770318\n",
      "current accuracy:  0.10714285714285714\n",
      "current accuracy:  0.10695422535211267\n",
      "current accuracy:  0.10676625659050967\n",
      "current accuracy:  0.10657894736842105\n",
      "current accuracy:  0.10726795096322242\n",
      "current accuracy:  0.10708041958041958\n",
      "current accuracy:  0.10689354275741711\n",
      "current accuracy:  0.10670731707317073\n",
      "current accuracy:  0.10652173913043478\n",
      "current accuracy:  0.10633680555555555\n",
      "current accuracy:  0.1061525129982669\n",
      "current accuracy:  0.10596885813148789\n",
      "current accuracy:  0.10664939550949913\n",
      "current accuracy:  0.10646551724137931\n",
      "current accuracy:  0.10628227194492254\n",
      "current accuracy:  0.10609965635738831\n",
      "current accuracy:  0.10591766723842196\n",
      "current accuracy:  0.10573630136986302\n",
      "current accuracy:  0.10555555555555556\n",
      "current accuracy:  0.10537542662116041\n",
      "current accuracy:  0.10519591141396933\n",
      "current accuracy:  0.1050170068027211\n",
      "current accuracy:  0.10483870967741936\n",
      "current accuracy:  0.10466101694915254\n",
      "current accuracy:  0.10532994923857868\n",
      "current accuracy:  0.10515202702702703\n",
      "current accuracy:  0.10581787521079258\n",
      "current accuracy:  0.10648148148148148\n",
      "current accuracy:  0.10630252100840336\n",
      "current accuracy:  0.10612416107382551\n",
      "current accuracy:  0.10678391959798995\n",
      "current accuracy:  0.10660535117056856\n",
      "current accuracy:  0.10642737896494157\n",
      "current accuracy:  0.10625\n",
      "current accuracy:  0.10607321131447588\n",
      "current accuracy:  0.10589700996677741\n",
      "current accuracy:  0.10572139303482588\n",
      "current accuracy:  0.10554635761589404\n",
      "current accuracy:  0.10537190082644628\n",
      "current accuracy:  0.1051980198019802\n",
      "current accuracy:  0.10502471169686985\n",
      "current accuracy:  0.10485197368421052\n",
      "current accuracy:  0.10467980295566502\n",
      "current accuracy:  0.10532786885245901\n",
      "current accuracy:  0.10515548281505728\n",
      "current accuracy:  0.10498366013071896\n",
      "current accuracy:  0.10481239804241435\n",
      "current accuracy:  0.10464169381107492\n",
      "current accuracy:  0.10447154471544716\n",
      "current accuracy:  0.10511363636363637\n",
      "current accuracy:  0.10494327390599675\n",
      "current accuracy:  0.10477346278317153\n",
      "current accuracy:  0.10460420032310178\n",
      "current accuracy:  0.10443548387096774\n",
      "current accuracy:  0.10426731078904992\n",
      "current accuracy:  0.10409967845659164\n",
      "current accuracy:  0.10393258426966293\n",
      "current accuracy:  0.10376602564102565\n",
      "current accuracy:  0.1036\n",
      "current accuracy:  0.10343450479233227\n",
      "current accuracy:  0.1032695374800638\n",
      "current accuracy:  0.10310509554140128\n",
      "current accuracy:  0.1041335453100159\n",
      "current accuracy:  0.10396825396825397\n",
      "current accuracy:  0.1045958795562599\n",
      "current accuracy:  0.10522151898734178\n",
      "current accuracy:  0.10505529225908374\n",
      "current accuracy:  0.1056782334384858\n",
      "current accuracy:  0.10551181102362205\n",
      "current accuracy:  0.10534591194968554\n",
      "current accuracy:  0.10518053375196232\n",
      "current accuracy:  0.10501567398119123\n",
      "current accuracy:  0.10485133020344288\n",
      "current accuracy:  0.1046875\n",
      "current accuracy:  0.10452418096723869\n",
      "current accuracy:  0.10514018691588785\n",
      "current accuracy:  0.10497667185069985\n",
      "current accuracy:  0.10559006211180125\n",
      "current accuracy:  0.10542635658914729\n",
      "current accuracy:  0.10526315789473684\n",
      "current accuracy:  0.10510046367851623\n",
      "current accuracy:  0.10493827160493827\n",
      "current accuracy:  0.10477657935285054\n",
      "current accuracy:  0.10461538461538461\n",
      "current accuracy:  0.10445468509984639\n",
      "current accuracy:  0.10429447852760736\n",
      "current accuracy:  0.10413476263399694\n",
      "current accuracy:  0.10397553516819572\n",
      "current accuracy:  0.10381679389312977\n",
      "current accuracy:  0.10365853658536585\n",
      "current accuracy:  0.1035007610350076\n",
      "current accuracy:  0.1033434650455927\n",
      "current accuracy:  0.10318664643399089\n",
      "current accuracy:  0.10303030303030303\n",
      "current accuracy:  0.10287443267776097\n",
      "current accuracy:  0.10347432024169184\n",
      "current accuracy:  0.1033182503770739\n",
      "current accuracy:  0.10391566265060241\n",
      "current accuracy:  0.1037593984962406\n",
      "current accuracy:  0.10435435435435435\n",
      "current accuracy:  0.10494752623688156\n",
      "current accuracy:  0.10479041916167664\n",
      "current accuracy:  0.10463378176382661\n",
      "current accuracy:  0.10522388059701493\n",
      "current accuracy:  0.10581222056631892\n",
      "current accuracy:  0.1056547619047619\n",
      "current accuracy:  0.10549777117384844\n",
      "current accuracy:  0.10534124629080119\n",
      "current accuracy:  0.10518518518518519\n",
      "current accuracy:  0.10502958579881656\n",
      "current accuracy:  0.10487444608567208\n",
      "current accuracy:  0.10471976401179942\n",
      "current accuracy:  0.10456553755522828\n",
      "current accuracy:  0.10441176470588236\n",
      "current accuracy:  0.10425844346549193\n",
      "current accuracy:  0.10410557184750734\n",
      "current accuracy:  0.10395314787701318\n",
      "current accuracy:  0.10380116959064327\n",
      "current accuracy:  0.10364963503649635\n",
      "current accuracy:  0.10349854227405247\n",
      "current accuracy:  0.10334788937409024\n",
      "current accuracy:  0.10319767441860465\n",
      "current accuracy:  0.10304789550072568\n",
      "current accuracy:  0.1036231884057971\n",
      "current accuracy:  0.10347322720694646\n",
      "current accuracy:  0.10332369942196531\n",
      "current accuracy:  0.10317460317460317\n",
      "current accuracy:  0.10302593659942363\n",
      "current accuracy:  0.10287769784172662\n",
      "current accuracy:  0.10272988505747127\n",
      "current accuracy:  0.10258249641319943\n",
      "current accuracy:  0.10315186246418338\n",
      "current accuracy:  0.10371959942775394\n",
      "current accuracy:  0.10357142857142858\n",
      "current accuracy:  0.10342368045649072\n",
      "current accuracy:  0.10327635327635327\n",
      "current accuracy:  0.10384068278805121\n",
      "current accuracy:  0.10369318181818182\n",
      "current accuracy:  0.10354609929078014\n",
      "current accuracy:  0.10339943342776203\n",
      "current accuracy:  0.10325318246110325\n",
      "current accuracy:  0.10310734463276836\n",
      "current accuracy:  0.10296191819464035\n",
      "current accuracy:  0.1028169014084507\n",
      "current accuracy:  0.10267229254571027\n",
      "current accuracy:  0.10252808988764045\n",
      "current accuracy:  0.10238429172510519\n",
      "current accuracy:  0.10224089635854341\n",
      "current accuracy:  0.1020979020979021\n",
      "current accuracy:  0.10195530726256984\n",
      "current accuracy:  0.10181311018131102\n",
      "current accuracy:  0.10167130919220056\n",
      "current accuracy:  0.10222531293463143\n",
      "current accuracy:  0.10277777777777777\n",
      "current accuracy:  0.10263522884882108\n",
      "current accuracy:  0.10249307479224377\n",
      "current accuracy:  0.10338865836791147\n",
      "current accuracy:  0.10324585635359115\n",
      "current accuracy:  0.10310344827586207\n",
      "current accuracy:  0.10365013774104684\n",
      "current accuracy:  0.10350756533700138\n",
      "current accuracy:  0.10336538461538461\n",
      "current accuracy:  0.10322359396433471\n",
      "current accuracy:  0.10308219178082192\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.10280054644808743\n",
      "current accuracy:  0.10334242837653479\n",
      "current accuracy:  0.1032016348773842\n",
      "current accuracy:  0.10374149659863946\n",
      "current accuracy:  0.10360054347826086\n",
      "current accuracy:  0.10345997286295794\n",
      "current accuracy:  0.10331978319783197\n",
      "current accuracy:  0.10317997293640054\n",
      "current accuracy:  0.10371621621621621\n",
      "current accuracy:  0.10357624831309042\n",
      "current accuracy:  0.1034366576819407\n",
      "current accuracy:  0.10329744279946164\n",
      "current accuracy:  0.10315860215053764\n",
      "current accuracy:  0.10302013422818793\n",
      "current accuracy:  0.10355227882037533\n",
      "current accuracy:  0.10341365461847389\n",
      "current accuracy:  0.10327540106951871\n",
      "current accuracy:  0.10313751668891856\n",
      "current accuracy:  0.103\n",
      "current accuracy:  0.10286284953395473\n",
      "current accuracy:  0.10272606382978723\n",
      "current accuracy:  0.10258964143426295\n",
      "current accuracy:  0.10245358090185676\n",
      "current accuracy:  0.10331125827814569\n",
      "current accuracy:  0.10317460317460317\n",
      "current accuracy:  0.10303830911492734\n",
      "current accuracy:  0.10356200527704486\n",
      "current accuracy:  0.10342555994729907\n",
      "current accuracy:  0.10328947368421053\n",
      "current accuracy:  0.1038107752956636\n",
      "current accuracy:  0.1036745406824147\n",
      "current accuracy:  0.10419397116644823\n",
      "current accuracy:  0.10405759162303665\n",
      "current accuracy:  0.10392156862745099\n",
      "current accuracy:  0.10378590078328982\n",
      "current accuracy:  0.10365058670143416\n",
      "current accuracy:  0.103515625\n",
      "current accuracy:  0.1033810143042913\n",
      "current accuracy:  0.10324675324675325\n",
      "current accuracy:  0.10311284046692606\n",
      "current accuracy:  0.10297927461139897\n",
      "current accuracy:  0.10284605433376455\n",
      "current accuracy:  0.10271317829457365\n",
      "current accuracy:  0.10258064516129033\n",
      "current accuracy:  0.10309278350515463\n",
      "current accuracy:  0.10296010296010295\n",
      "current accuracy:  0.10282776349614396\n",
      "current accuracy:  0.10269576379974327\n",
      "current accuracy:  0.10256410256410256\n",
      "current accuracy:  0.10243277848911651\n",
      "current accuracy:  0.10230179028132992\n",
      "current accuracy:  0.10280970625798212\n",
      "current accuracy:  0.10267857142857142\n",
      "current accuracy:  0.10254777070063695\n",
      "current accuracy:  0.10241730279898219\n",
      "current accuracy:  0.102287166454892\n",
      "current accuracy:  0.10215736040609137\n",
      "current accuracy:  0.10266159695817491\n",
      "current accuracy:  0.10253164556962026\n",
      "current accuracy:  0.10240202275600506\n",
      "current accuracy:  0.10227272727272728\n",
      "current accuracy:  0.10308953341740228\n",
      "current accuracy:  0.10295969773299748\n",
      "current accuracy:  0.10283018867924529\n",
      "current accuracy:  0.10332914572864321\n",
      "current accuracy:  0.10319949811794228\n",
      "current accuracy:  0.10307017543859649\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.10375\n",
      "current accuracy:  0.10362047440699126\n",
      "current accuracy:  0.10349127182044887\n",
      "current accuracy:  0.10336239103362391\n",
      "current accuracy:  0.10323383084577115\n",
      "current accuracy:  0.1031055900621118\n",
      "current accuracy:  0.10297766749379653\n",
      "current accuracy:  0.10285006195786865\n",
      "current accuracy:  0.1036509900990099\n",
      "current accuracy:  0.10352286773794808\n",
      "current accuracy:  0.10339506172839506\n",
      "current accuracy:  0.10388409371146733\n",
      "current accuracy:  0.10375615763546799\n",
      "current accuracy:  0.10362853628536285\n",
      "current accuracy:  0.1035012285012285\n",
      "current accuracy:  0.10337423312883436\n",
      "current accuracy:  0.10324754901960784\n",
      "current accuracy:  0.10312117503059975\n",
      "current accuracy:  0.10360635696821516\n",
      "current accuracy:  0.10347985347985347\n",
      "current accuracy:  0.10335365853658536\n",
      "current accuracy:  0.10322777101096224\n",
      "current accuracy:  0.1031021897810219\n",
      "current accuracy:  0.10358444714459296\n",
      "current accuracy:  0.10345873786407767\n",
      "current accuracy:  0.10333333333333333\n",
      "current accuracy:  0.10320823244552058\n",
      "current accuracy:  0.10308343409915356\n",
      "current accuracy:  0.10295893719806763\n",
      "current accuracy:  0.10283474065138722\n",
      "current accuracy:  0.10271084337349398\n",
      "current accuracy:  0.10258724428399518\n",
      "current accuracy:  0.1024639423076923\n",
      "current accuracy:  0.10234093637454982\n",
      "current accuracy:  0.10221822541966427\n",
      "current accuracy:  0.10269461077844311\n",
      "current accuracy:  0.10257177033492823\n",
      "current accuracy:  0.10244922341696536\n",
      "current accuracy:  0.1029236276849642\n",
      "current accuracy:  0.10280095351609059\n",
      "current accuracy:  0.10267857142857142\n",
      "current accuracy:  0.1025564803804994\n",
      "current accuracy:  0.10243467933491686\n",
      "current accuracy:  0.10231316725978648\n",
      "current accuracy:  0.10219194312796208\n",
      "current accuracy:  0.10207100591715976\n",
      "current accuracy:  0.10195035460992907\n",
      "current accuracy:  0.10182998819362456\n",
      "current accuracy:  0.10170990566037735\n",
      "current accuracy:  0.10217903415783275\n",
      "current accuracy:  0.10264705882352941\n",
      "current accuracy:  0.10252643948296122\n",
      "current accuracy:  0.10240610328638497\n",
      "current accuracy:  0.10228604923798358\n",
      "current accuracy:  0.10216627634660422\n",
      "current accuracy:  0.102046783625731\n",
      "current accuracy:  0.10192757009345794\n",
      "current accuracy:  0.10239206534422404\n",
      "current accuracy:  0.10227272727272728\n",
      "current accuracy:  0.10215366705471478\n",
      "current accuracy:  0.10261627906976745\n",
      "current accuracy:  0.10249709639953543\n",
      "current accuracy:  0.10295823665893271\n",
      "current accuracy:  0.10283893395133256\n",
      "current accuracy:  0.1032986111111111\n",
      "current accuracy:  0.10317919075144509\n",
      "current accuracy:  0.10306004618937645\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.1028225806451613\n",
      "current accuracy:  0.1027042577675489\n",
      "current accuracy:  0.10258620689655172\n",
      "current accuracy:  0.10246842709529276\n",
      "current accuracy:  0.10235091743119266\n",
      "current accuracy:  0.10223367697594501\n",
      "current accuracy:  0.1026887871853547\n",
      "current accuracy:  0.10314285714285715\n",
      "current accuracy:  0.10302511415525115\n",
      "current accuracy:  0.10290763968072976\n",
      "current accuracy:  0.10279043280182232\n",
      "current accuracy:  0.10267349260523322\n",
      "current accuracy:  0.10255681818181818\n",
      "current accuracy:  0.10244040862656073\n",
      "current accuracy:  0.10232426303854875\n",
      "current accuracy:  0.1022083805209513\n",
      "current accuracy:  0.10209276018099547\n",
      "current accuracy:  0.10197740112994351\n",
      "current accuracy:  0.10186230248306997\n",
      "current accuracy:  0.10174746335963923\n",
      "current accuracy:  0.10247747747747747\n",
      "current accuracy:  0.10292463442069741\n",
      "current accuracy:  0.10280898876404494\n",
      "current accuracy:  0.1026936026936027\n",
      "current accuracy:  0.10257847533632287\n",
      "current accuracy:  0.10246360582306831\n",
      "current accuracy:  0.10234899328859061\n",
      "current accuracy:  0.10223463687150838\n",
      "current accuracy:  0.10212053571428571\n",
      "current accuracy:  0.1020066889632107\n",
      "current accuracy:  0.10189309576837416\n",
      "current accuracy:  0.10233592880978866\n",
      "current accuracy:  0.10277777777777777\n",
      "current accuracy:  0.10266370699223086\n",
      "current accuracy:  0.10254988913525499\n",
      "current accuracy:  0.10243632336655592\n",
      "current accuracy:  0.10232300884955753\n",
      "current accuracy:  0.10220994475138122\n",
      "current accuracy:  0.1020971302428256\n",
      "current accuracy:  0.1019845644983462\n",
      "current accuracy:  0.10187224669603524\n",
      "current accuracy:  0.10176017601760176\n",
      "current accuracy:  0.10164835164835165\n",
      "current accuracy:  0.10153677277716795\n",
      "current accuracy:  0.10197368421052631\n",
      "current accuracy:  0.10240963855421686\n",
      "current accuracy:  0.10229759299781181\n",
      "current accuracy:  0.10273224043715846\n",
      "current accuracy:  0.10262008733624454\n",
      "current accuracy:  0.10305343511450382\n",
      "current accuracy:  0.10294117647058823\n",
      "current accuracy:  0.10282916213275299\n",
      "current accuracy:  0.10271739130434783\n",
      "current accuracy:  0.10260586319218241\n",
      "current accuracy:  0.10249457700650759\n",
      "current accuracy:  0.10238353196099675\n",
      "current accuracy:  0.10227272727272728\n",
      "current accuracy:  0.10270270270270271\n",
      "current accuracy:  0.10313174946004319\n",
      "current accuracy:  0.10302049622437973\n",
      "current accuracy:  0.10290948275862069\n",
      "current accuracy:  0.10279870828848224\n",
      "current accuracy:  0.10268817204301076\n",
      "current accuracy:  0.10257787325456498\n",
      "current accuracy:  0.10246781115879829\n",
      "current accuracy:  0.10235798499464094\n",
      "current accuracy:  0.10224839400428265\n",
      "current accuracy:  0.10213903743315508\n",
      "current accuracy:  0.10202991452991453\n",
      "current accuracy:  0.10192102454642477\n",
      "current accuracy:  0.10181236673773987\n",
      "current accuracy:  0.10170394036208733\n",
      "current accuracy:  0.10159574468085106\n",
      "current accuracy:  0.10148777895855472\n",
      "current accuracy:  0.10138004246284502\n",
      "current accuracy:  0.10127253446447508\n",
      "current accuracy:  0.10116525423728813\n",
      "current accuracy:  0.10105820105820106\n",
      "current accuracy:  0.10095137420718817\n",
      "current accuracy:  0.10084477296726505\n",
      "current accuracy:  0.10073839662447258\n",
      "current accuracy:  0.10063224446786091\n",
      "current accuracy:  0.10052631578947369\n",
      "current accuracy:  0.10042060988433228\n",
      "current accuracy:  0.10084033613445378\n",
      "current accuracy:  0.10073452256033578\n",
      "current accuracy:  0.10062893081761007\n",
      "current accuracy:  0.10052356020942409\n",
      "current accuracy:  0.10094142259414227\n",
      "current accuracy:  0.10083594566353186\n",
      "current accuracy:  0.10073068893528184\n",
      "current accuracy:  0.10062565172054223\n",
      "current accuracy:  0.10052083333333334\n",
      "current accuracy:  0.1004162330905307\n",
      "current accuracy:  0.10083160083160084\n",
      "current accuracy:  0.10072689511941849\n",
      "current accuracy:  0.10062240663900415\n",
      "current accuracy:  0.10051813471502591\n",
      "current accuracy:  0.10041407867494824\n",
      "current accuracy:  0.10031023784901758\n",
      "current accuracy:  0.10098140495867769\n",
      "current accuracy:  0.10087719298245613\n",
      "current accuracy:  0.10077319587628866\n",
      "current accuracy:  0.10066941297631309\n",
      "current accuracy:  0.10056584362139917\n",
      "current accuracy:  0.10046248715313463\n",
      "current accuracy:  0.10035934291581108\n",
      "current accuracy:  0.10025641025641026\n",
      "current accuracy:  0.10015368852459017\n",
      "current accuracy:  0.10005117707267144\n",
      "current accuracy:  0.09994887525562372\n",
      "current accuracy:  0.10035750766087845\n",
      "current accuracy:  0.10025510204081632\n",
      "current accuracy:  0.10015290519877676\n",
      "current accuracy:  0.10005091649694502\n",
      "current accuracy:  0.09994913530010173\n",
      "current accuracy:  0.09984756097560976\n",
      "current accuracy:  0.09974619289340102\n",
      "current accuracy:  0.09964503042596348\n",
      "current accuracy:  0.09954407294832827\n",
      "current accuracy:  0.09994939271255061\n",
      "current accuracy:  0.09984833164812942\n",
      "current accuracy:  0.09974747474747475\n",
      "current accuracy:  0.0996468213925328\n",
      "current accuracy:  0.09954637096774194\n",
      "current accuracy:  0.09944612286002014\n",
      "current accuracy:  0.09984909456740443\n",
      "current accuracy:  0.09974874371859296\n",
      "current accuracy:  0.09964859437751004\n",
      "current accuracy:  0.09954864593781344\n",
      "current accuracy:  0.09944889779559118\n",
      "current accuracy:  0.09934934934934934\n",
      "current accuracy:  0.09975\n",
      "current accuracy:  0.10014985014985014\n",
      "current accuracy:  0.1000499001996008\n",
      "current accuracy:  0.09995014955134596\n",
      "current accuracy:  0.10034860557768924\n",
      "current accuracy:  0.10024875621890547\n",
      "current accuracy:  0.10014910536779324\n",
      "current accuracy:  0.10004965243296922\n",
      "current accuracy:  0.09995039682539683\n",
      "current accuracy:  0.10034687809712586\n",
      "current accuracy:  0.10024752475247525\n",
      "current accuracy:  0.10014836795252226\n",
      "current accuracy:  0.10004940711462451\n",
      "current accuracy:  0.09995064165844028\n",
      "current accuracy:  0.09985207100591716\n",
      "current accuracy:  0.09975369458128079\n",
      "current accuracy:  0.09965551181102363\n",
      "current accuracy:  0.09955752212389381\n",
      "current accuracy:  0.09945972495088409\n",
      "current accuracy:  0.09985279685966635\n",
      "current accuracy:  0.09975490196078432\n",
      "current accuracy:  0.09965719882468169\n",
      "current accuracy:  0.09955968688845401\n",
      "current accuracy:  0.09946236559139784\n",
      "current accuracy:  0.099853515625\n",
      "current accuracy:  0.09975609756097562\n",
      "current accuracy:  0.0996588693957115\n",
      "current accuracy:  0.09956183057448881\n",
      "current accuracy:  0.09995136186770429\n",
      "current accuracy:  0.09985422740524781\n",
      "current accuracy:  0.09975728155339805\n",
      "current accuracy:  0.09966052376333656\n",
      "current accuracy:  0.09956395348837209\n",
      "current accuracy:  0.10019361084220717\n",
      "current accuracy:  0.10058027079303675\n",
      "current accuracy:  0.10048309178743961\n",
      "current accuracy:  0.10038610038610038\n",
      "current accuracy:  0.10028929604628736\n",
      "current accuracy:  0.1001926782273603\n",
      "current accuracy:  0.10009624639076034\n",
      "current accuracy:  0.1\n",
      "current accuracy:  0.09990393852065321\n",
      "current accuracy:  0.09980806142034548\n",
      "current accuracy:  0.09971236816874401\n",
      "current accuracy:  0.09961685823754789\n",
      "current accuracy:  0.09952153110047847\n",
      "current accuracy:  0.09990439770554493\n",
      "current accuracy:  0.09980897803247374\n",
      "current accuracy:  0.09971374045801527\n",
      "current accuracy:  0.10009532888465204\n",
      "current accuracy:  0.10071428571428571\n",
      "current accuracy:  0.10061845861084681\n",
      "current accuracy:  0.10099809885931559\n",
      "current accuracy:  0.10090218423551757\n",
      "current accuracy:  0.10128083491461101\n",
      "current accuracy:  0.1018957345971564\n",
      "current accuracy:  0.10179924242424243\n",
      "current accuracy:  0.10170293282876064\n",
      "current accuracy:  0.10160680529300567\n",
      "current accuracy:  0.10151085930122758\n",
      "current accuracy:  0.1018867924528302\n",
      "current accuracy:  0.10179076343072573\n",
      "current accuracy:  0.1016949152542373\n",
      "current accuracy:  0.10159924741298212\n",
      "current accuracy:  0.10220864661654136\n",
      "current accuracy:  0.10211267605633803\n",
      "current accuracy:  0.10201688555347092\n",
      "current accuracy:  0.10192127460168697\n",
      "current accuracy:  0.1022940074906367\n",
      "current accuracy:  0.10219831618334893\n",
      "current accuracy:  0.10210280373831776\n",
      "current accuracy:  0.10200746965452848\n",
      "current accuracy:  0.10191231343283583\n",
      "current accuracy:  0.10181733457595527\n",
      "current accuracy:  0.10218808193668528\n",
      "current accuracy:  0.10209302325581396\n",
      "current accuracy:  0.10199814126394052\n",
      "current accuracy:  0.10190343546889508\n",
      "current accuracy:  0.10180890538033395\n",
      "current accuracy:  0.10171455050973123\n",
      "current accuracy:  0.10162037037037037\n",
      "current accuracy:  0.1015263644773358\n",
      "current accuracy:  0.10143253234750461\n",
      "current accuracy:  0.10133887349953832\n",
      "current accuracy:  0.10124538745387454\n",
      "current accuracy:  0.1011520737327189\n",
      "current accuracy:  0.10105893186003684\n",
      "current accuracy:  0.10096596136154554\n",
      "current accuracy:  0.10087316176470588\n",
      "current accuracy:  0.10078053259871442\n",
      "current accuracy:  0.10068807339449541\n",
      "current accuracy:  0.10059578368469294\n",
      "current accuracy:  0.10050366300366301\n",
      "current accuracy:  0.10041171088746569\n",
      "current accuracy:  0.10077696526508227\n",
      "current accuracy:  0.10114155251141553\n",
      "current accuracy:  0.1010492700729927\n",
      "current accuracy:  0.10095715587967183\n",
      "current accuracy:  0.10086520947176685\n",
      "current accuracy:  0.10077343039126478\n",
      "current accuracy:  0.10113636363636364\n",
      "current accuracy:  0.10104450499545867\n",
      "current accuracy:  0.1014065335753176\n",
      "current accuracy:  0.10131459655485041\n",
      "current accuracy:  0.10122282608695653\n",
      "current accuracy:  0.10113122171945702\n",
      "current accuracy:  0.10103978300180831\n",
      "current accuracy:  0.10094850948509485\n",
      "current accuracy:  0.1013086642599278\n",
      "current accuracy:  0.10121731289449955\n",
      "current accuracy:  0.10112612612612612\n",
      "current accuracy:  0.10103510351035104\n",
      "current accuracy:  0.10139388489208633\n",
      "current accuracy:  0.10130278526504942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(testloader):  \n\u001b[1;32m      7\u001b[0m     images, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m     z, _ \u001b[39m=\u001b[39m model(images) \u001b[39m# f(z)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images)): \u001b[39m# iterate through images\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(z[j] \u001b[39m-\u001b[39m z, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[171], line 12\u001b[0m, in \u001b[0;36mSimSiam.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     13\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# TODO\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[1;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# knn test accuracy\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_predicted = 0\n",
    "    total_predicted = 0\n",
    "    for i, data in enumerate(testloader):  \n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        z, _ = model(images) # f(z)\n",
    "        for j in range(len(images)): # iterate through images\n",
    "            dist = torch.norm(z[j] - z, dim=1, p=None)\n",
    "            knn = dist.topk(4, largest=False) # NOTE: Remove first one, it's distance to itself\n",
    "            # get index\n",
    "            indices = knn.indices[1:]\n",
    "            # get label of element at index\n",
    "            classes = labels[indices]\n",
    "            # maximum vote\n",
    "            predicted_label, _ = torch.mode(classes)\n",
    "            true_label = labels[j]\n",
    "            if true_label == predicted_label:\n",
    "                true_predicted += 1\n",
    "            total_predicted += 1\n",
    "        print(\"current accuracy: \", true_predicted/total_predicted)\n",
    "\n",
    "print(\"accuracy = \", true_predicted/total_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
